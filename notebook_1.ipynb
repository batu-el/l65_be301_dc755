{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufd2y4shgKa-",
        "outputId": "ebc886a9-563b-45db-f35f-67a248aa7766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing PyTorch Geometric\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing other libraries\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (3.2.1)\n",
            "Requirement already satisfied: lovely-tensors in ./.venv/lib/python3.10/site-packages (0.1.15)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (from lovely-tensors) (2.1.0)\n",
            "Requirement already satisfied: lovely-numpy>=0.2.9 in ./.venv/lib/python3.10/site-packages (from lovely-tensors) (0.2.11)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.26.4)\n",
            "Requirement already satisfied: fastcore in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.5.29)\n",
            "Requirement already satisfied: ipython in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (8.21.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (3.8.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (4.9.0)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (1.12)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.1.3)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->lovely-tensors) (12.3.101)\n",
            "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (24.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (23.2)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.17.2)\n",
            "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (5.14.1)\n",
            "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch->lovely-tensors) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch->lovely-tensors) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.16.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install networkx\n",
        "    !pip install lovely-tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLyuVVPLgOfR",
        "outputId": "56384d33-7956-453d-fdde-fe93867313a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ],
      "source": [
        "# Import python modules\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, TransformerEncoder, TransformerEncoderLayer, LayerNorm, Module, ModuleList\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import GNNBenchmarkDataset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
        "\n",
        "import lovely_tensors as lt\n",
        "lt.monkey_patch()\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iNWHUdDGR5q",
        "outputId": "b62451c0-42a1-40e5-8ecb-43b68d8a7d1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_538632/3418808368.py:12: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import ortho_group\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import Planetoid, QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocE2TaQ7gUhC",
        "outputId": "d364ae4d-ba76-4ee9-b44e-afe70c5f430a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All seeds set.\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BeKO33tXK1Cq"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper functions for unit testing\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 1\n",
        "################################\n",
        "\n",
        "def get_dummy_data_transductive():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1680148244],\n",
        "        [0.3310719728],\n",
        "        [0.2041909844],\n",
        "        [0.2041909844]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_layer():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1086086035],\n",
        "        [0.1543375552],\n",
        "        [0.1992474943],\n",
        "        [0.1992474943]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_model():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[-0.0814725384]])\n",
        "    return A, x, y\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 2\n",
        "################################\n",
        "\n",
        "def get_dummy_data():\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 1]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 2]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [1, 2, 3]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "\n",
        "\n",
        "# Invariant Dummies\n",
        "def dummy_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos\n",
        "\n",
        "def dummy_invariant(x, pos, edge_index, edge_attr):\n",
        "    return x\n",
        "\n",
        "def dummy_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos - torch.unsqueeze(pos[0], dim=0)\n",
        "\n",
        "def dummy_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return torch.sum(pos * torch.unsqueeze(pos[0], dim=0), dim=-1)\n",
        "\n",
        "\n",
        "# Equivariant Dummies\n",
        "def dummy_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos\n",
        "\n",
        "def dummy_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, 2 * pos + 2\n",
        "\n",
        "def dummy_h_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, pos\n",
        "\n",
        "def dummy_x_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos + 2\n",
        "\n",
        "def dummy_h_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_trans_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_h_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_rot_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_x_only_trans_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos + 2\n",
        "\n",
        "def dummy_x_only_rot_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qz4WMK5F205",
        "outputId": "79a4e26b-b123-4741-f560-d1532431fbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ],
      "source": [
        "# @title [RUN] Helper functions for managing experiments, training, and evaluating models\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "\n",
        "print(\"Helper functions loaded.\")\n",
        "\n",
        "\n",
        "def train_gnn_cora(X, y, mask, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(X)[mask]\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "\n",
        "def evaluate_gnn_cora(X, y, mask, model):\n",
        "    model.eval()\n",
        "    y_hat = model(X)[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, train_x, train_y, train_mask,\n",
        "                        valid_x, valid_y, valid_mask,\n",
        "                        test_x, test_y, test_mask\n",
        "                    ):\n",
        "    optimiser = Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, train_y, train_mask, model, optimiser)\n",
        "        train_acc = evaluate_gnn_cora(train_x, train_y, train_mask, model)\n",
        "        valid_acc = evaluate_gnn_cora(valid_x, valid_y, valid_mask, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_gnn_cora(test_x, test_y, test_mask, model)\n",
        "    print(f\"Our final test accuracy for the SimpleGNN is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CVWk1k0OESAM"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] `CoraDataset` implementation\n",
        "# Let's get the Planetoid Cora dataset from\n",
        "# â€œFastGCN: Fast Learning with Graph Convolutional\n",
        "# Networks via Importance Samplingâ€ (https://arxiv.org/abs/1801.10247)\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "class CoraDataset(object):\n",
        "    def __init__(self):\n",
        "        super(CoraDataset, self).__init__()\n",
        "        cora_pyg = Planetoid(root='/tmp/Cora', name='Cora', split=\"full\")\n",
        "        self.cora_data = cora_pyg[0]\n",
        "        self.train_mask = self.cora_data.train_mask\n",
        "        self.valid_mask = self.cora_data.val_mask\n",
        "        self.test_mask = self.cora_data.test_mask\n",
        "\n",
        "    def train_val_test_split(self):\n",
        "        train_x = self.cora_data.x[self.cora_data.train_mask]\n",
        "        train_y = self.cora_data.y[self.cora_data.train_mask]\n",
        "\n",
        "        valid_x = self.cora_data.x[self.cora_data.val_mask]\n",
        "        valid_y = self.cora_data.y[self.cora_data.val_mask]\n",
        "\n",
        "        test_x = self.cora_data.x[self.cora_data.test_mask]\n",
        "        test_y = self.cora_data.y[self.cora_data.test_mask]\n",
        "        return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "    def get_fullx(self):\n",
        "        return self.cora_data.x\n",
        "\n",
        "    def get_adjacency_matrix(self):\n",
        "        # We will ignore this for the first part\n",
        "        adj = to_dense_adj(self.cora_data.edge_index)[0]\n",
        "        return adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSHOy-IESGl",
        "outputId": "c8614a91-b450-46e7-8716-1ed471d440db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape x: torch.Size([1208, 1433]), y: torch.Size([1208])\n",
            "Val shape x: torch.Size([500, 1433]), y: torch.Size([500])\n",
            "Test shape x: torch.Size([1000, 1433]), y: torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "# Lets download our cora dataset and get the splits\n",
        "cora_data = CoraDataset()\n",
        "train_x, train_y, valid_x, valid_y, test_x, test_y = cora_data.train_val_test_split()\n",
        "\n",
        "# Always check and confirm our data shapes match our expectations\n",
        "print(f\"Train shape x: {train_x.shape}, y: {train_y.shape}\")\n",
        "print(f\"Val shape x: {valid_x.shape}, y: {valid_y.shape}\")\n",
        "print(f\"Test shape x: {test_x.shape}, y: {test_y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qJsvuuphESJf"
      },
      "outputs": [],
      "source": [
        "# Fill in the initialisation and forward method the GCNLayer below\n",
        "\n",
        "class GCNLayer(Module):\n",
        "    \"\"\"Graph Convolutional Network layer from Kipf & Welling.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        self.A_hat = A + torch.eye(A.size(0))                                 # A + I\n",
        "        D_hat = torch.diag(torch.pow(self.A_hat.sum(1), -0.5))                # D^(-1/2)\n",
        "        self.adj_norm = torch.matmul(torch.matmul(D_hat, self.A_hat), D_hat)  # D^(-1/2) A D^(-1/2)\n",
        "        self.linear = Linear(input_dim, output_dim)                           # W\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implements the forward pass for the layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node feature matrix\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        print(x)\n",
        "        x = torch.matmul(self.adj_norm, x)  # Aggregate neighbor information\n",
        "        x = self.linear(x)  # Apply linear transformation W\n",
        "        x = F.relu(x)  # Apply non-linearity\n",
        "        # ===========================================\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCWshjveK6wz",
        "outputId": "7ebfe55a-831b-45ed-eb8a-f34280262bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor[4, 64] n=256 (1Kb) xâˆˆ[0.001, 0.997] Î¼=0.477 Ïƒ=0.285\n",
            "tensor[4, 64] n=256 (1Kb) xâˆˆ[0.001, 0.997] Î¼=0.477 Ïƒ=0.285\n",
            "âœ… All seems good!!!\n"
          ]
        }
      ],
      "source": [
        "# @title âœ… [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_transductive()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer(input_dim, output_dim, A)\n",
        "  out = model(x)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Oops! ðŸ¤­ Output shape is wrong\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model_perm = GCNLayer(input_dim, output_dim, A_perm)\n",
        "\n",
        "  out_model_perm = model_perm(perm_x)\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is not permutation equivariant anymore ðŸ¥º\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is wrong.\"\n",
        "  print(\"âœ… All seems good!!!\")\n",
        "\n",
        "\n",
        "# run unit test function\n",
        "testing_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UDGFNRjRESOA"
      },
      "outputs": [],
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "\n",
        "class SimpleGNN(Module):\n",
        "    \"\"\"A Simple GNN model using the GCNLayer for node classification\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_gcn_layers, A):\n",
        "        super(SimpleGNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # Note: if a single layer is used hidden_dim should be the same as input_dim\n",
        "        if num_gcn_layers > 1:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, hidden_dim, A)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, hidden_dim, A) for i in range(num_gcn_layers-2)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, output_dim, A)]\n",
        "        else:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, output_dim, A)]\n",
        "\n",
        "        self.gcn_layers = ModuleList(self.gcn_layers)\n",
        "        self.num_gcn_layers = num_gcn_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleGNN on input x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "        \"\"\"\n",
        "        for j in range(self.num_gcn_layers-1):\n",
        "          x = self.gcn_layers[j](x)\n",
        "          x = F.relu(x)\n",
        "\n",
        "        x = self.gcn_layers[-1](x)\n",
        "\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Wsxg2ymuGm8z"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "vLa5PwkhFoQl",
        "outputId": "c57bb451-d3ce-4e2b-e439-fee3ec566b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 0 with train loss: 1.943 train accuracy: 26.325 validation accuracy: 29.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 10 with train loss: 1.868 train accuracy: 55.298 validation accuracy: 51.400\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 20 with train loss: 1.785 train accuracy: 66.474 validation accuracy: 60.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 30 with train loss: 1.704 train accuracy: 74.172 validation accuracy: 66.800\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 40 with train loss: 1.624 train accuracy: 79.222 validation accuracy: 71.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 50 with train loss: 1.544 train accuracy: 83.030 validation accuracy: 73.800\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 60 with train loss: 1.468 train accuracy: 85.844 validation accuracy: 76.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 70 with train loss: 1.396 train accuracy: 88.493 validation accuracy: 80.600\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 80 with train loss: 1.328 train accuracy: 89.901 validation accuracy: 80.400\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 90 with train loss: 1.265 train accuracy: 90.397 validation accuracy: 82.600\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Our final test accuracy for the SimpleGNN is: 82.900\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN(input_dim=train_x.shape[-1], output_dim=7, A=A, hidden_dim=train_x.shape[-1], num_gcn_layers=1)\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "O19jAscEHQY_"
      },
      "outputs": [],
      "source": [
        "# Fill in the initialisation and forward method the GCNLayer below\n",
        "\n",
        "class GCNLayer_Transformer(Module):\n",
        "    \"\"\"Graph Convolutional Network layer from Kipf & Welling.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer_Transformer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        self.multihead_attn = torch.nn.MultiheadAttention(input_dim, 1)\n",
        "        self.transformer_encoder =  TransformerEncoderLayer(d_model = input_dim, nhead = 1, dim_feedforward = 128, batch_first = True, norm_first = True)\n",
        "        self.linear = Linear(input_dim, output_dim)\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implements the forward pass for the layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node feature matrix\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # x = self.multihead_attn(x, x, x)[0]\n",
        "        x = self.transformer_encoder(x, A)\n",
        "        x = self.linear(x)\n",
        "        # x = F.relu(x)\n",
        "        # ===========================================\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "YjwKWAYmKlEg",
        "outputId": "18fffc96-c17c-4c2c-bbc0-ba88d53ced97"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The shape of the 2D attn_mask is torch.Size([2708, 2708]), but should be (4, 4).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… All seems good!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# run unit test function\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtesting_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[18], line 12\u001b[0m, in \u001b[0;36mtesting_gcn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNLayer_Transformer(input_dim, output_dim, A)\n\u001b[0;32m---> 12\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], output_dim)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOops! ðŸ¤­ Output shape is wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m perm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[17], line 31\u001b[0m, in \u001b[0;36mGCNLayer_Transformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implements the forward pass for the layer\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    x (torch.Tensor): input node feature matrix\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ============ YOUR CODE HERE ==============\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# x = self.multihead_attn(x, x, x)[0]\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# x = F.relu(x)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# ===========================================\u001b[39;00m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:704\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    702\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n\u001b[0;32m--> 704\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5318\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5316\u001b[0m     correct_2d_size \u001b[38;5;241m=\u001b[39m (tgt_len, src_len)\n\u001b[1;32m   5317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m correct_2d_size:\n\u001b[0;32m-> 5318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the 2D attn_mask is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_2d_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5319\u001b[0m     attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   5320\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The shape of the 2D attn_mask is torch.Size([2708, 2708]), but should be (4, 4)."
          ]
        }
      ],
      "source": [
        "# @title âœ… [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_transductive()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer_Transformer(input_dim, output_dim, A)\n",
        "  out = model(x)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Oops! ðŸ¤­ Output shape is wrong\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model_perm = GCNLayer_Transformer(input_dim, output_dim, A_perm)\n",
        "\n",
        "  out_model_perm = model_perm(perm_x)\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is not permutation equivariant anymore ðŸ¥º\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is wrong.\"\n",
        "  print(\"âœ… All seems good!!!\")\n",
        "\n",
        "# run unit test function\n",
        "testing_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FkTY3lVxJXTv"
      },
      "outputs": [],
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "\n",
        "class SimpleGNN_Transformer(Module):\n",
        "    \"\"\"A Simple GNN model using the GCNLayer for node classification\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_gcn_layers, A):\n",
        "        super(SimpleGNN_Transformer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # Note: if a single layer is used hidden_dim should be the same as input_dim\n",
        "        if num_gcn_layers > 1:\n",
        "          self.gcn_layers = [GCNLayer_Transformer(input_dim, hidden_dim, A)]\n",
        "          self.gcn_layers += [GCNLayer_Transformer(hidden_dim, hidden_dim, A) for i in range(num_gcn_layers-2)]\n",
        "          self.gcn_layers += [GCNLayer_Transformer(hidden_dim, output_dim, A)]\n",
        "        else:\n",
        "          self.gcn_layers = [GCNLayer_Transformer(input_dim, output_dim, A)]\n",
        "\n",
        "        self.gcn_layers = ModuleList(self.gcn_layers)\n",
        "        self.num_gcn_layers = num_gcn_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleGNN on input x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "        \"\"\"\n",
        "        for j in range(self.num_gcn_layers-1):\n",
        "          x = self.gcn_layers[j](x)\n",
        "          x = F.relu(x)\n",
        "          \n",
        "\n",
        "        x = self.gcn_layers[-1](x)\n",
        "\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "asFFYMJWFu9i"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "DZeBUHKzKRfC",
        "outputId": "7a4bae1c-5076-4672-a4a5-30ca5e621f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 with train loss: 1.979 train accuracy: 28.228 validation accuracy: 31.600\n",
            "Epoch 10 with train loss: 0.476 train accuracy: 91.142 validation accuracy: 67.000\n",
            "Epoch 20 with train loss: 0.012 train accuracy: 99.917 validation accuracy: 68.200\n",
            "Epoch 30 with train loss: 0.006 train accuracy: 100.000 validation accuracy: 69.000\n",
            "Epoch 40 with train loss: 0.001 train accuracy: 100.000 validation accuracy: 68.000\n",
            "Epoch 50 with train loss: 0.004 train accuracy: 100.000 validation accuracy: 67.800\n",
            "Epoch 60 with train loss: 0.014 train accuracy: 100.000 validation accuracy: 66.400\n",
            "Epoch 70 with train loss: 0.002 train accuracy: 100.000 validation accuracy: 67.800\n",
            "Epoch 80 with train loss: 0.004 train accuracy: 100.000 validation accuracy: 69.400\n",
            "Epoch 90 with train loss: 0.007 train accuracy: 99.834 validation accuracy: 68.000\n",
            "Our final test accuracy for the SimpleGNN is: 69.900\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN_Transformer(input_dim=train_x.shape[-1], output_dim=7, A=A, hidden_dim=train_x.shape[-1], num_gcn_layers=1)\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNwZuLEEKU8W"
      },
      "outputs": [],
      "source": [
        "# hetrophilic task -> attending to everythig is better\n",
        "# homophilic task -> attending to graph is good\n",
        "\n",
        "# dont use cora !! --- highly homophilic\n",
        "# control homophily\n",
        "\n",
        "# cyclic object\n",
        "\n",
        "# get some results - do not fail the project\n",
        "# logit you can fit the forward pass and\n",
        "\n",
        "\n",
        "# if you want to switch from inductive and transductive\n",
        "# only modify the loss and not the forward pass\n",
        "\n",
        "# start with inductive.\n",
        "# contibue with transductive.\n",
        "\n",
        "\n",
        "# Use CLRS\n",
        "# --> NAR dataset\n",
        "# --> graph trnsformers\n",
        "\n",
        "\n",
        "# how well GNNs deal with over squashing?\n",
        "\n",
        "\n",
        "\n",
        "# 1. homophilly in the ocntext of transformer and GNN\n",
        "\n",
        "# Graph former\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
