{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufd2y4shgKa-",
        "outputId": "ebc886a9-563b-45db-f35f-67a248aa7766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing PyTorch Geometric\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing other libraries\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (3.2.1)\n",
            "Requirement already satisfied: lovely-tensors in ./.venv/lib/python3.10/site-packages (0.1.15)\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (from lovely-tensors) (2.1.0)\n",
            "Requirement already satisfied: lovely-numpy>=0.2.9 in ./.venv/lib/python3.10/site-packages (from lovely-tensors) (0.2.11)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.26.4)\n",
            "Requirement already satisfied: fastcore in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.5.29)\n",
            "Requirement already satisfied: ipython in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (8.21.0)\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (from lovely-numpy>=0.2.9->lovely-tensors) (3.8.2)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (4.9.0)\n",
            "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (1.12)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (3.1.3)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch->lovely-tensors) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->lovely-tensors) (12.3.101)\n",
            "Requirement already satisfied: pip in ./.venv/lib/python3.10/site-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (24.0)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (23.2)\n",
            "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.17.2)\n",
            "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (5.14.1)\n",
            "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch->lovely-tensors) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch->lovely-tensors) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.16.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install networkx\n",
        "    !pip install lovely-tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLyuVVPLgOfR",
        "outputId": "56384d33-7956-453d-fdde-fe93867313a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ],
      "source": [
        "# Import python modules\n",
        "\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, TransformerEncoder, TransformerEncoderLayer, LayerNorm, Module, ModuleList\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import GNNBenchmarkDataset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
        "\n",
        "import lovely_tensors as lt\n",
        "lt.monkey_patch()\n",
        "\n",
        "from torch.optim import Adam\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iNWHUdDGR5q",
        "outputId": "b62451c0-42a1-40e5-8ecb-43b68d8a7d1c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_433728/3418808368.py:12: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import ortho_group\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import Planetoid, QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocE2TaQ7gUhC",
        "outputId": "d364ae4d-ba76-4ee9-b44e-afe70c5f430a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All seeds set.\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BeKO33tXK1Cq"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper functions for unit testing\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 1\n",
        "################################\n",
        "\n",
        "def get_dummy_data_transductive():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1680148244],\n",
        "        [0.3310719728],\n",
        "        [0.2041909844],\n",
        "        [0.2041909844]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_layer():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[0.1086086035],\n",
        "        [0.1543375552],\n",
        "        [0.1992474943],\n",
        "        [0.1992474943]])\n",
        "    return A, x, y\n",
        "\n",
        "def get_dummy_data_inductive_model():\n",
        "    input_dim = 64\n",
        "    A = torch.tensor([[0, 1, 1, 0],\n",
        "        [1, 0, 0, 0],\n",
        "        [1, 1, 0, 1],\n",
        "        [1, 1, 1, 0]])\n",
        "    x = torch.rand(A.shape[0], input_dim)\n",
        "    y = torch.tensor([[-0.0814725384]])\n",
        "    return A, x, y\n",
        "\n",
        "################################\n",
        "# Dummy data helpers for Part 2\n",
        "################################\n",
        "\n",
        "def get_dummy_data():\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 1]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [0, 0, 2]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "    yield Batch(\n",
        "        x=torch.Tensor([[1], [1]]),\n",
        "        pos=torch.Tensor([[0, 0, 0], [1, 2, 3]]),\n",
        "        edge_index=torch.LongTensor([[0, 1], [1, 0]]),\n",
        "        edge_attr=torch.Tensor([[1], [1]]),\n",
        "    )\n",
        "\n",
        "\n",
        "# Invariant Dummies\n",
        "def dummy_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos\n",
        "\n",
        "def dummy_invariant(x, pos, edge_index, edge_attr):\n",
        "    return x\n",
        "\n",
        "def dummy_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos - torch.unsqueeze(pos[0], dim=0)\n",
        "\n",
        "def dummy_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return torch.sum(pos * torch.unsqueeze(pos[0], dim=0), dim=-1)\n",
        "\n",
        "\n",
        "# Equivariant Dummies\n",
        "def dummy_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos\n",
        "\n",
        "def dummy_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, 2 * pos + 2\n",
        "\n",
        "def dummy_h_not_invariant(x, pos, edge_index, edge_attr):\n",
        "    return pos, pos\n",
        "\n",
        "def dummy_x_not_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos + 2\n",
        "\n",
        "def dummy_h_only_trans_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_trans_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_h_only_rot_invariant(x, pos, edge_index, edge_attr):\n",
        "    return dummy_only_rot_invariant(x, pos, edge_index, edge_attr), pos\n",
        "\n",
        "def dummy_x_only_trans_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, pos + 2\n",
        "\n",
        "def dummy_x_only_rot_equivariant(x, pos, edge_index, edge_attr):\n",
        "    return x, 2 * pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qz4WMK5F205",
        "outputId": "79a4e26b-b123-4741-f560-d1532431fbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ],
      "source": [
        "# @title [RUN] Helper functions for managing experiments, training, and evaluating models\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "\n",
        "print(\"Helper functions loaded.\")\n",
        "\n",
        "\n",
        "def train_gnn_cora(X, y, mask, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(X)[mask]\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "\n",
        "def evaluate_gnn_cora(X, y, mask, model):\n",
        "    model.eval()\n",
        "    y_hat = model(X)[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, train_x, train_y, train_mask,\n",
        "                        valid_x, valid_y, valid_mask,\n",
        "                        test_x, test_y, test_mask\n",
        "                    ):\n",
        "    optimiser = Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, train_y, train_mask, model, optimiser)\n",
        "        train_acc = evaluate_gnn_cora(train_x, train_y, train_mask, model)\n",
        "        valid_acc = evaluate_gnn_cora(valid_x, valid_y, valid_mask, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_gnn_cora(test_x, test_y, test_mask, model)\n",
        "    print(f\"Our final test accuracy for the SimpleGNN is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CVWk1k0OESAM"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] `CoraDataset` implementation\n",
        "# Let's get the Planetoid Cora dataset from\n",
        "# â€œFastGCN: Fast Learning with Graph Convolutional\n",
        "# Networks via Importance Samplingâ€ (https://arxiv.org/abs/1801.10247)\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "class CoraDataset(object):\n",
        "    def __init__(self):\n",
        "        super(CoraDataset, self).__init__()\n",
        "        cora_pyg = Planetoid(root='/tmp/Cora', name='Cora', split=\"full\")\n",
        "        self.cora_data = cora_pyg[0]\n",
        "        self.train_mask = self.cora_data.train_mask\n",
        "        self.valid_mask = self.cora_data.val_mask\n",
        "        self.test_mask = self.cora_data.test_mask\n",
        "\n",
        "    def train_val_test_split(self):\n",
        "        train_x = self.cora_data.x[self.cora_data.train_mask]\n",
        "        train_y = self.cora_data.y[self.cora_data.train_mask]\n",
        "\n",
        "        valid_x = self.cora_data.x[self.cora_data.val_mask]\n",
        "        valid_y = self.cora_data.y[self.cora_data.val_mask]\n",
        "\n",
        "        test_x = self.cora_data.x[self.cora_data.test_mask]\n",
        "        test_y = self.cora_data.y[self.cora_data.test_mask]\n",
        "        return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "    def get_fullx(self):\n",
        "        return self.cora_data.x\n",
        "\n",
        "    def get_adjacency_matrix(self):\n",
        "        # We will ignore this for the first part\n",
        "        adj = to_dense_adj(self.cora_data.edge_index)[0]\n",
        "        return adj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmSHOy-IESGl",
        "outputId": "c8614a91-b450-46e7-8716-1ed471d440db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape x: torch.Size([1208, 1433]), y: torch.Size([1208])\n",
            "Val shape x: torch.Size([500, 1433]), y: torch.Size([500])\n",
            "Test shape x: torch.Size([1000, 1433]), y: torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "# Lets download our cora dataset and get the splits\n",
        "cora_data = CoraDataset()\n",
        "train_x, train_y, valid_x, valid_y, test_x, test_y = cora_data.train_val_test_split()\n",
        "\n",
        "# Always check and confirm our data shapes match our expectations\n",
        "print(f\"Train shape x: {train_x.shape}, y: {train_y.shape}\")\n",
        "print(f\"Val shape x: {valid_x.shape}, y: {valid_y.shape}\")\n",
        "print(f\"Test shape x: {test_x.shape}, y: {test_y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qJsvuuphESJf"
      },
      "outputs": [],
      "source": [
        "# Fill in the initialisation and forward method the GCNLayer below\n",
        "\n",
        "class GCNLayer(Module):\n",
        "    \"\"\"Graph Convolutional Network layer from Kipf & Welling.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        self.A_hat = A + torch.eye(A.size(0))                                 # A + I\n",
        "        D_hat = torch.diag(torch.pow(self.A_hat.sum(1), -0.5))                # D^(-1/2)\n",
        "        self.adj_norm = torch.matmul(torch.matmul(D_hat, self.A_hat), D_hat)  # D^(-1/2) A D^(-1/2)\n",
        "        self.linear = Linear(input_dim, output_dim)                           # W\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implements the forward pass for the layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node feature matrix\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        print(x)\n",
        "        x = torch.matmul(self.adj_norm, x)  # Aggregate neighbor information\n",
        "        x = self.linear(x)  # Apply linear transformation W\n",
        "        x = F.relu(x)  # Apply non-linearity\n",
        "        # ===========================================\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCWshjveK6wz",
        "outputId": "7ebfe55a-831b-45ed-eb8a-f34280262bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor[4, 64] n=256 (1Kb) xâˆˆ[0.001, 0.997] Î¼=0.477 Ïƒ=0.285\n",
            "tensor[4, 64] n=256 (1Kb) xâˆˆ[0.001, 0.997] Î¼=0.477 Ïƒ=0.285\n",
            "âœ… All seems good!!!\n"
          ]
        }
      ],
      "source": [
        "# @title âœ… [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_transductive()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer(input_dim, output_dim, A)\n",
        "  out = model(x)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Oops! ðŸ¤­ Output shape is wrong\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model_perm = GCNLayer(input_dim, output_dim, A_perm)\n",
        "\n",
        "  out_model_perm = model_perm(perm_x)\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is not permutation equivariant anymore ðŸ¥º\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is wrong.\"\n",
        "  print(\"âœ… All seems good!!!\")\n",
        "\n",
        "\n",
        "# run unit test function\n",
        "testing_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UDGFNRjRESOA"
      },
      "outputs": [],
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "\n",
        "class SimpleGNN(Module):\n",
        "    \"\"\"A Simple GNN model using the GCNLayer for node classification\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_gcn_layers, A):\n",
        "        super(SimpleGNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # Note: if a single layer is used hidden_dim should be the same as input_dim\n",
        "        if num_gcn_layers > 1:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, hidden_dim, A)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, hidden_dim, A) for i in range(num_gcn_layers-2)]\n",
        "          self.gcn_layers += [GCNLayer(hidden_dim, output_dim, A)]\n",
        "        else:\n",
        "          self.gcn_layers = [GCNLayer(input_dim, output_dim, A)]\n",
        "\n",
        "        self.gcn_layers = ModuleList(self.gcn_layers)\n",
        "        self.num_gcn_layers = num_gcn_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleGNN on input x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "        \"\"\"\n",
        "        for j in range(self.num_gcn_layers-1):\n",
        "          x = self.gcn_layers[j](x)\n",
        "          x = F.relu(x)\n",
        "\n",
        "        x = self.gcn_layers[-1](x)\n",
        "\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Wsxg2ymuGm8z"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "vLa5PwkhFoQl",
        "outputId": "c57bb451-d3ce-4e2b-e439-fee3ec566b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 0 with train loss: 1.943 train accuracy: 26.325 validation accuracy: 29.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 10 with train loss: 1.868 train accuracy: 55.298 validation accuracy: 51.400\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 20 with train loss: 1.785 train accuracy: 66.474 validation accuracy: 60.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 30 with train loss: 1.704 train accuracy: 74.172 validation accuracy: 66.800\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 40 with train loss: 1.624 train accuracy: 79.222 validation accuracy: 71.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 50 with train loss: 1.544 train accuracy: 83.030 validation accuracy: 73.800\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 60 with train loss: 1.468 train accuracy: 85.844 validation accuracy: 76.200\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 70 with train loss: 1.396 train accuracy: 88.493 validation accuracy: 80.600\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 80 with train loss: 1.328 train accuracy: 89.901 validation accuracy: 80.400\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Epoch 90 with train loss: 1.265 train accuracy: 90.397 validation accuracy: 82.600\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "tensor[2708, 1433] n=3880564 (15Mb) xâˆˆ[0., 1.000] Î¼=0.013 Ïƒ=0.112\n",
            "Our final test accuracy for the SimpleGNN is: 82.900\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN(input_dim=train_x.shape[-1], output_dim=7, A=A, hidden_dim=train_x.shape[-1], num_gcn_layers=1)\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "O19jAscEHQY_"
      },
      "outputs": [],
      "source": [
        "# Fill in the initialisation and forward method the GCNLayer below\n",
        "\n",
        "class GCNLayer_Transformer(Module):\n",
        "    \"\"\"Graph Convolutional Network layer from Kipf & Welling.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer_Transformer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        self.multihead_attn = torch.nn.MultiheadAttention(input_dim, 1)\n",
        "        self.transformer_encoder =  TransformerEncoderLayer(d_model = input_dim, nhead = 1, dim_feedforward = 128, batch_first = True, norm_first = True)\n",
        "        self.linear = Linear(input_dim, output_dim)\n",
        "        # ===========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Implements the forward pass for the layer\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node feature matrix\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        x = self.multihead_attn(x, x, x)[0]\n",
        "        # x = self.transformer_encoder(x, A)\n",
        "        x = self.linear(x)\n",
        "        # x = F.relu(x)\n",
        "        # ===========================================\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "YjwKWAYmKlEg",
        "outputId": "18fffc96-c17c-4c2c-bbc0-ba88d53ced97"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The shape of the 2D attn_mask is torch.Size([2708, 2708]), but should be (4, 4).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… All seems good!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# run unit test function\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtesting_gcn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mtesting_gcn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m torch\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNLayer_Transformer(input_dim, output_dim, A)\n\u001b[0;32m---> 12\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m(out\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], output_dim)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOops! ðŸ¤­ Output shape is wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m perm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mpermutation(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[14], line 29\u001b[0m, in \u001b[0;36mGCNLayer_Transformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implements the forward pass for the layer\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    x (torch.Tensor): input node feature matrix\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ============ YOUR CODE HERE ==============\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[1;32m     31\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:704\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    702\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n\u001b[0;32m--> 704\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:715\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    714\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 715\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
            "File \u001b[0;32m~/l65_be301_dc755/.venv/lib/python3.10/site-packages/torch/nn/functional.py:5318\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5316\u001b[0m     correct_2d_size \u001b[38;5;241m=\u001b[39m (tgt_len, src_len)\n\u001b[1;32m   5317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m correct_2d_size:\n\u001b[0;32m-> 5318\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the 2D attn_mask is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_mask\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorrect_2d_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5319\u001b[0m     attn_mask \u001b[38;5;241m=\u001b[39m attn_mask\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   5320\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m attn_mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The shape of the 2D attn_mask is torch.Size([2708, 2708]), but should be (4, 4)."
          ]
        }
      ],
      "source": [
        "# @title âœ… [RUN] **Please run this unit test to validate your code. The output would be used to mark your practical.**\n",
        "def testing_gcn():\n",
        "  torch.random.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "  A,x,y = get_dummy_data_transductive()\n",
        "\n",
        "  input_dim = x.shape[-1]\n",
        "  output_dim = y.shape[-1]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model = GCNLayer_Transformer(input_dim, output_dim, A)\n",
        "  out = model(x)\n",
        "\n",
        "  assert(out.shape == (A.shape[0], output_dim)), \"Oops! ðŸ¤­ Output shape is wrong\"\n",
        "\n",
        "  perm = np.random.permutation(x.shape[0])\n",
        "  perm_x = x[perm]\n",
        "  perm_out = out[perm]\n",
        "  A_perm = A[perm, :][:, perm]\n",
        "\n",
        "  torch.random.manual_seed(0)\n",
        "  model_perm = GCNLayer_Transformer(input_dim, output_dim, A_perm)\n",
        "\n",
        "  out_model_perm = model_perm(perm_x)\n",
        "  assert (torch.allclose(perm_out, out_model_perm, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is not permutation equivariant anymore ðŸ¥º\"\n",
        "\n",
        "  assert (torch.allclose(out, y, atol=1e-6)), \"ðŸ¤” Something is wrong in the model! The output is wrong.\"\n",
        "  print(\"âœ… All seems good!!!\")\n",
        "\n",
        "# run unit test function\n",
        "testing_gcn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FkTY3lVxJXTv"
      },
      "outputs": [],
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "\n",
        "class SimpleGNN_Transformer(Module):\n",
        "    \"\"\"A Simple GNN model using the GCNLayer for node classification\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_gcn_layers, A):\n",
        "        super(SimpleGNN_Transformer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # Note: if a single layer is used hidden_dim should be the same as input_dim\n",
        "        if num_gcn_layers > 1:\n",
        "          self.gcn_layers = [GCNLayer_Transformer(input_dim, hidden_dim, A)]\n",
        "          self.gcn_layers += [GCNLayer_Transformer(hidden_dim, hidden_dim, A) for i in range(num_gcn_layers-2)]\n",
        "          self.gcn_layers += [GCNLayer_Transformer(hidden_dim, output_dim, A)]\n",
        "        else:\n",
        "          self.gcn_layers = [GCNLayer_Transformer(input_dim, output_dim, A)]\n",
        "\n",
        "        self.gcn_layers = ModuleList(self.gcn_layers)\n",
        "        self.num_gcn_layers = num_gcn_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through SimpleGNN on input x\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): input node features\n",
        "        \"\"\"\n",
        "        for j in range(self.num_gcn_layers-1):\n",
        "          x = self.gcn_layers[j](x)\n",
        "          x = F.relu(x)\n",
        "          \n",
        "\n",
        "        x = self.gcn_layers[-1](x)\n",
        "\n",
        "        y_hat = x\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "asFFYMJWFu9i"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "DZeBUHKzKRfC",
        "outputId": "7a4bae1c-5076-4672-a4a5-30ca5e621f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 with train loss: 1.944 train accuracy: 28.228 validation accuracy: 31.600\n",
            "Epoch 10 with train loss: 1.840 train accuracy: 28.228 validation accuracy: 31.600\n",
            "Epoch 20 with train loss: 1.729 train accuracy: 30.132 validation accuracy: 31.800\n",
            "Epoch 30 with train loss: 1.287 train accuracy: 45.778 validation accuracy: 36.400\n",
            "Epoch 40 with train loss: 1.007 train accuracy: 56.291 validation accuracy: 37.000\n",
            "Epoch 50 with train loss: 0.767 train accuracy: 69.950 validation accuracy: 34.000\n",
            "Epoch 60 with train loss: 0.524 train accuracy: 83.113 validation accuracy: 33.400\n",
            "Epoch 70 with train loss: 0.292 train accuracy: 92.053 validation accuracy: 31.800\n",
            "Epoch 80 with train loss: 0.107 train accuracy: 98.344 validation accuracy: 34.600\n",
            "Epoch 90 with train loss: 0.037 train accuracy: 99.338 validation accuracy: 35.800\n",
            "Our final test accuracy for the SimpleGNN is: 40.000\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAHWCAYAAAARoQJ4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrTklEQVR4nO3deVhUZfvA8e8M+zqIC4sCoqKgoqmo4b5QuGRqmmmWmpYtWpmvaf5KW81cstIWq7dXWzSXUivNTHE3d8V9lwQRcEH2feb8/jgyOiIKCMwA9+e65oo555kz95yEe55doyiKghBCCCGKTGvuAIQQQoiKRpKnEEIIUUySPIUQQohikuQphBBCFJMkTyGEEKKYJHkKIYQQxSTJUwghhCgmSZ5CCCFEMUnyFEIIIYpJkqcQQghRTJI8hShnUVFRjB07loYNG+Lo6IijoyONGzdmzJgxHD582FjunXfeQaPR4OHhQUZGRoHr1K1bl0ceecTkmEajQaPR8PHHHxcov3DhQjQaDfv27St2zCkpKbz77rs0b94cZ2dnHBwcaNq0KZMmTeLSpUvFvp4QFZ21uQMQoipZvXo1TzzxBNbW1gwdOpTmzZuj1Wo5efIkK1as4KuvviIqKgo/Pz/jay5fvsxXX33Ff/7znyK/z6xZs3jxxRdxdHS875jPnz9PWFgY0dHRPP7444wePRpbW1sOHz7Md999x8qVKzl9+vR9v48QFYkkTyHKyblz5xg8eDB+fn5ERETg5eVlcn7GjBl8+eWXaLWmDUIPPPAAs2bN4qWXXsLBweGe7/PAAw8QGRnJ/PnzGT9+/H3FnJeXx2OPPUZCQgKbN2+mQ4cOJuenTZvGjBkz7us98qWnp+Pk5FQq1xKirEmzrRDlZObMmaSnp7NgwYICiRPA2tqaV155BR8fH5PjU6dOJSEhga+++qpI79O+fXu6devGzJkzyczMvK+Yf/31Vw4dOsSbb75ZIHECuLq6Mm3aNJNjy5cvp1WrVjg4OFCjRg2eeuopYmNjTcqMGDECZ2dnzp07R69evXBxcWHo0KEAbNu2jccffxxfX1/s7Ozw8fHhtddeu+/PIkRpkuQpRDlZvXo1DRo0oG3btsV6XceOHYudDN95551iJdzC/P777wA8/fTTRSq/cOFCBg0ahJWVFdOnT+e5555jxYoVdOjQgaSkJJOyeXl5hIeHU6tWLWbPns2AAQMANflmZGTw4osvMm/ePMLDw5k3bx7Dhg27r88iRKlShBBlLjk5WQGUfv36FTh3/fp15cqVK8ZHRkaGoiiK8vbbbyuAcuXKFWXLli0KoMyZM8f4Oj8/P6V3794m1wKUMWPGKIqiKF27dlU8PT2N11uwYIECKHv37i1y3C1atFB0Ol2Ryubk5Ci1atVSmjZtqmRmZhqPr169WgGUqVOnGo8NHz5cAZQ33nijwHXy473V9OnTFY1Go1y4cKHIsQtRlqTmKUQ5SElJAcDZ2bnAuS5dulCzZk3j44svvihQplOnTnTt2rXYtc/4+Hjmz59/X3G7uLgUqey+ffu4fPkyL730Evb29sbjvXv3JjAwkDVr1hR4zYsvvljg2K39uunp6Vy9epV27dqhKAoHDx4swacQovRJ8hSiHOQnoLS0tALnvv76a9avX89PP/1012sUNxmWJOHeztXVldTU1CKVvXDhAgCNGjUqcC4wMNB4Pp+1tTV16tQpUDY6OpoRI0bg7u6Os7MzNWvWpHPnzgAkJycX9yMIUSZktK0Q5UCn0+Hl5cXRo0cLnMvvA/3333/veo1OnTrRpUsXZs6cyQsvvFCk93377bfp0qULX3/9NW5ubsUNm8DAQA4ePEhMTEyBgUz3y87OrsDIYr1ez0MPPURiYiKTJk0iMDAQJycnYmNjGTFiBAaDoVRjEKKkpOYpRDnp3bs3Z8+eZc+ePSW+Rn7t8+uvvy5S+c6dO9OlSxdmzJhRotpnnz59AO5ZKwaMc1NPnTpV4NypU6dM5q4W5siRI5w+fZqPP/6YSZMm0bdvX8LCwvD29i5m5EKULUmeQpSTiRMn4ujoyMiRI0lISChwXlGUe17j1mSYlZVVpPfNT7jffPNNsWMeOHAgwcHBTJs2jZ07dxY4n5qayptvvglASEgItWrVYv78+WRnZxvLrF27lhMnTtC7d+97vp+VlRVgei8UReGzzz4rduxClCVpthWinAQEBLB48WKGDBlCo0aNjCsMKYpCVFQUixcvRqvV3rEf8FZvv/02Xbt2LfL7du7cmc6dO7Nly5Zix2xjY8OKFSsICwujU6dODBo0iPbt22NjY8OxY8dYvHgx1apVY9q0adjY2DBjxgyeeeYZOnfuzJAhQ0hISOCzzz6jbt26vPbaa/d8v8DAQOrXr8+ECROIjY3F1dWVX3/9levXrxc7diHKlFnH+gpRBZ09e1Z58cUXlQYNGij29vaKg4ODEhgYqLzwwgtKZGSksdytU1Vu17lzZwW461SVW23atEkBij1VJd/169eVqVOnKsHBwYqjo6Nib2+vNG3aVJk8ebISFxdnUnbp0qVKixYtFDs7O8Xd3V0ZOnSocvHiRZMyw4cPV5ycnO74XsePH1fCwsIUZ2dnpUaNGspzzz2nHDp0SAGUBQsWFDt2IcqCRlGK0FYkhBBCCCPp8xRCCCGKSfo8haiCcnJySExMvGsZnU5XpIXohaiKJHkKUQX9888/9xx0tGDBAkaMGFE+AQlRwUifpxBV0PXr19m/f/9dyzRp0uSOu78IISR5CiGEEMUmA4aEEEKIYpI+T8BgMHDp0iVcXFzQaDTmDkcIIYQZKIpCamoq3t7eBdZdvp0kT+DSpUulvui1EEKIiikmJuaeK31J8uTmdlExMTG4urqaORohhBDmkJKSgo+PT5H2sJXkCcamWldXV0meQghRxRWl+04GDAkhhBDFJMlTCCGEKCZJnkIIIUQxSZ9nEen1enJzc80dhqigrKyssLa2lqlQQlQSkjyLIC0tjYsXLyKLMYn74ejoiJeXF7a2tuYORQhxnyR53oNer+fixYs4OjpSs2ZNqTmIYlMUhZycHK5cuUJUVBQBAQH3nIAthLBskjzvITc3F0VRqFmzpmzPJErMwcEBGxsbLly4QE5ODvb29uYOSQhxH+TrbxFJjVPcL6ltClF5mPW3eevWrfTp0wdvb280Gg2rVq0yOa8oClOnTsXLywsHBwfCwsI4c+aMSZnExESGDh2Kq6srbm5ujBo1irS0tHL8FEIIIaoasybP9PR0mjdvzhdffHHH8zNnzmTu3LnMnz+f3bt34+TkRHh4OFlZWcYyQ4cO5dixY6xfv57Vq1ezdetWRo8eXV4fQQghRFWkWAhAWblypfG5wWBQPD09lVmzZhmPJSUlKXZ2dsrPP/+sKIqiHD9+XAGUvXv3GsusXbtW0Wg0SmxsbJHfOzk5WQGU5OTkAucyMzOV48ePK5mZmSX4VJWLn5+f8sknnxS5/KZNmxRAuX79epnFVJHIvyUhLNvdcsHtLLYTJioqivj4eMLCwozHdDodbdu2ZefOnQDs3LkTNzc3QkJCjGXCwsLQarXs3r273GO2FBqN5q6Pd955p0TX3bt3b7Fq9e3atSMuLg6dTlei9xNCCEtlsaNt4+PjAfDw8DA57uHhYTwXHx9PrVq1TM5bW1vj7u5uLHMn2dnZZGdnG5+npKSUVtgWIS4uzvjz0qVLmTp1KqdOnTIec3Z2Nv6sKAp6vR5r63v/U6hZs2ax4rC1tcXT07NYrxFCiIrAYpNnWZo+fTrvvvtuiV6rKAqZufpSjqhoHGysijTq99aEpdPp0Gg0xmObN2+ma9eu/Pnnn7z11lscOXKEv//+Gx8fH8aPH8+uXbtIT08nKCiI6dOnm9T869aty7hx4xg3bhyg1nC//fZb1qxZw7p166hduzYff/wxjz76qMl7Xb9+HTc3NxYuXMi4ceNYunQp48aNIyYmhg4dOrBgwQK8vLwAyMvLY/z48fzwww9YWVnx7LPPEh8fT3JycoEBZfmuXbvG2LFj2bp1K9evX6d+/fr83//9H0OGDDGWMRgMzJ49m2+++YaYmBg8PDx4/vnnefPNNwG4ePEir7/+OuvWrSM7O5ugoCC++OIL2rZtW/T/QUIIQP07mZKZx6XkTOKSM4lNyiIuKZO45CwuJWWSnFk2q7U90syLsd0CyuTat7PY5Jn/xz4hIcH4hzX/+QMPPGAsc/nyZZPX5eXlkZiYeNcaz+TJkxk/frzxef4ebkWRmaun8dR1Rf0Yper4e+E42pbO/7I33niD2bNnU69ePapVq0ZMTAy9evVi2rRp2NnZ8cMPP9CnTx9OnTqFr69vodd59913mTlzJrNmzWLevHkMHTqUCxcu4O7ufsfyGRkZzJ49mx9//BGtVstTTz3FhAkTWLRoEQAzZsxg0aJFLFiwgKCgID777DNWrVpF165dC40hKyuLVq1aMWnSJFxdXVmzZg1PP/009evXp02bNoD6//zbb7/lk08+oUOHDsTFxXHy5ElAXUGqc+fO1K5dm99//x1PT08OHDiAwWAo6e0VotLJyTNw4Vo67k62uDvZGr/IGwwK19JzuHAtnYPRSey7kMj+C0lcTcu+xxVLX+u6d/67UxYsNnn6+/vj6elJRESEMVmmpKSwe/duXnzxRQBCQ0NJSkpi//79tGrVCoCNGzdiMBjuWmOws7PDzs6uzD+DJXvvvfd46KGHjM/d3d1p3ry58fn777/PypUr+f333xk7dmyh1xkxYoSxhvfhhx8yd+5c9uzZQ48ePe5YPjc3l/nz51O/fn0Axo4dy3vvvWc8P2/ePCZPnkz//v0B+Pzzz/nzzz/v+llq167NhAkTjM9ffvll1q1bx7Jly2jTpg2pqal89tlnfP755wwfPhyA+vXr06FDBwAWL17MlStX2Lt3rzHpN2jQ4K7vKURVkKc3sPP8NVYfiuOvY/HGGqOdtRZvNwf0BoX45Cxy9Hf+ounuZIuXzh4vnQPebjf/6+5ki4bSnzvvqSu/xUfMmjzT0tI4e/as8XlUVBSRkZG4u7vj6+vLuHHj+OCDDwgICMDf358pU6bg7e1Nv379AAgKCqJHjx4899xzzJ8/n9zcXMaOHcvgwYPx9vYuk5gdbKw4/l54mVy7KO9dWm4dZAXq/4t33nmHNWvWEBcXR15eHpmZmURHR9/1Os2aNTP+7OTkhKura4HWgFs5OjoaEyeAl5eXsXxycjIJCQnG2iKoC6q3atXqrrVAvV7Phx9+yLJly4iNjSUnJ4fs7GwcHR0BOHHiBNnZ2XTv3v2Or4+MjKRFixaF1paFqKwURSE6MYPoxAzikrLUZtb8/yZnEXs906SbysHGisxcPdl5BqKuphuPazTg4WJPcB0dIX7VaOVXjcberqXWUmaJzPrJ9u3bZ9Icl9+UOnz4cBYuXMjEiRNJT09n9OjRJCUl0aFDB/766y+Tpc0WLVrE2LFj6d69O1qtlgEDBjB37twyi1mj0VSKfxBOTk4mzydMmMD69euZPXs2DRo0wMHBgYEDB5KTk3PX69jY2Jg812g0d010dyqv3OeC+7NmzeKzzz7j008/JTg4GCcnJ8aNG2eM/V7LKsqyi6IqOZOQyoYTl9l/4ToHoq+TmH733/Fqjjb0DPaiTzNv2vi7k2cwkJCczaXkTLQaDd5u9ni42mNjZbGTN8qEWbNAly5d7vqHU6PR8N5775k0693O3d2dxYsXl0V4VcqOHTsYMWKEsbk0LS2Nf//9t1xj0Ol0eHh4sHfvXjp16gSotcoDBw4Ym+7vZMeOHfTt25ennnoKUAcHnT59msaNGwMQEBCAg4MDERERPPvsswVe36xZM/773/+SmJgotU9RKSmKwq7ziXyz9RybTl0xOWdrrcXP3REvNwdq32ha9dLZ4+2m/tfX3RHrWxKjldYK3+qO+FZ3LO+PYVEqfhVKlIqAgABWrFhBnz590Gg0TJkyxSwDZl5++WWmT59OgwYNCAwMZN68eVy/fv2uo4wDAgL45Zdf+Oeff6hWrRpz5swhISHBmDzt7e2ZNGkSEydOxNbWlvbt23PlyhWOHTvGqFGjGDJkCB9++CH9+vVj+vTpeHl5cfDgQby9vQkNDS2vjy5EkaVl53E4JonzV9OJu9HUeiUtG0MhlZGrqTmcSkgF1CbWro1q0a5+dVr6VaOJtyt21qXXJVRVSPIUAMyZM4eRI0fSrl07atSowaRJk8wy/3XSpEnEx8czbNgwrKysGD16NOHh4VhZFf7L/dZbb3H+/HnCw8NxdHRk9OjR9OvXj+TkZGOZKVOmYG1tzdSpU7l06RJeXl688MILgDof9e+//+Y///kPvXr1Ii8vj8aNGxe6bKQQ5rD/QiK/RV5i/4XrnIhLwVDM3g47ay2Ph9Th2Q71qFvD6d4vEHelUe63w6kSSElJQafTkZycjKurq8m5rKwsoqKi8Pf3l22kzMBgMBAUFMSgQYN4//33zR3OfZF/S6K49AaF9ccT+GbrOQ5EJ5mcq+3mQJCXy43mVQdqudhhbXXnFhprrZYH67lT3blqzzK4l7vlgttJzVNYlAsXLvD333/TuXNnsrOz+fzzz4mKiuLJJ580d2hClKvjl1J4ZclBzl5Wd4mytdLy6APedG1Ui1Z+1cp1WoYoSJKnsCharZaFCxcyYcIEFEWhadOmbNiwgaCgIHOHJkS5+S0ylkm/HiYr14DOwYanHvRleLu61HKRhGkpJHkKi+Lj48OOHTvMHYYQZpGnN/DR2pP8d3sUAJ0a1mTu4Adwc7Q1c2TidpI8hRDCAiSm5zB28QH+OXcNgJe61Oc/DzfCSlv6K/GI+yfJUwghzOxobDLP/7if2KRMHG2tmP14c3oFe937hcJsJHkKIYQZrTx4kTd+PUJ2noG61R35ZlgIDT1czB2WuAdJnkIIYSb/3XaeD9acAKBLo5p89kQLdI4293iVsASSPIUQwgwW7ogyJs7nO9djYnig9G9WIJI8hRCinC3afYF3/jgOwNiuDfjPww2LtNG9sBxVaxl8USxdunRh3Lhxxud169bl008/vetrNBoNq1atuu/3Lq3rCGFplu2N4c2VRwEY3ameJM4KSpJnJdSnT59CN6Petm0bGo2Gw4cPF/u6e/fuZfTo0fcbnol33nnnjjumxMXF0bNnz1J9LyHM7dut55n4q/q7N6JdXSb3DJTEWUFJs20lNGrUKAYMGMDFixepU6eOybkFCxYQEhJisol1UdWsWbO0QrwnT0/PcnsvIUpTdp6eF37cz9W0HJ4O9aPvA97YWmn5aO1Jvt56HoBRHfx5q3eQJM4KTGqexaUokJNunkcR1/B/5JFHqFmzJgsXLjQ5npaWxvLlyxk1ahTXrl1jyJAh1K5dG0dHR4KDg/n555/vet3bm23PnDlDp06dsLe3p3Hjxqxfv77AayZNmkTDhg1xdHSkXr16TJkyhdzcXAAWLlzIu+++y6FDh9BoNGg0GmPMtzfbHjlyhG7duuHg4ED16tUZPXo0aWlpxvMjRoygX79+zJ49Gy8vL6pXr86YMWOM73Un586do2/fvnh4eODs7Ezr1q3ZsGGDSZns7GwmTZqEj48PdnZ2NGjQgO+++854/tixYzzyyCO4urri4uJCx44dOXfu3F3vo6jcpv95kk2nrnAkNpmJvxym44xNDPvfHmPifKNnoCTOSkBqnsWVmwEfepvnvf/vEtjeeysha2trhg0bxsKFC3nzzTeNv6TLly9Hr9czZMgQ0tLSaNWqFZMmTcLV1ZU1a9bw9NNPU79+fdq0aXPP9zAYDDz22GN4eHiwe/dukpOTTfpH87m4uLBw4UK8vb05cuQIzz33HC4uLkycOJEnnniCo0eP8tdffxmTlk6nK3CN9PR0wsPDCQ0NZe/evVy+fJlnn32WsWPHmnxB2LRpE15eXmzatImzZ8/yxBNP8MADD/Dcc8/d8TOkpaXRq1cvpk2bhp2dHT/88AN9+vTh1KlT+Pr6AjBs2DB27tzJ3Llzad68OVFRUVy9ehWA2NhYOnXqRJcuXdi4cSOurq7s2LGDvLy8e94/UTltOJ7Awn/+BWBYqB9/H0sgPiWLy6nZaDXw0WPNGNTax7xBilIhybOSGjlyJLNmzWLLli106dIFUJtsBwwYgE6nQ6fTMWHCBGP5l19+mXXr1rFs2bIiJc8NGzZw8uRJ1q1bh7e3+mXiww8/LNBP+dZbbxl/rlu3LhMmTGDJkiVMnDgRBwcHnJ2dsba2vmsz7eLFi8nKyuKHH37AyUn98vD555/Tp08fZsyYgYeHBwDVqlXj888/x8rKisDAQHr37k1EREShybN58+Y0b97c+Pz9999n5cqV/P7774wdO5bTp0+zbNky1q9fT1hYGAD16tUzlv/iiy/Q6XQsWbIEGxt1bl7Dhg3vee9E5RSfnMXrvxwC1GbZKY805q3ejfnj0CXWHo1naFtfugbWMnOUorRI8iwuG0e1Bmiu9y6iwMBA2rVrx//+9z+6dOnC2bNn2bZtG++99x4Aer2eDz/8kGXLlhEbG0tOTg7Z2dk4OhbtPU6cOIGPj48xcQKEhoYWKLd06VLmzp3LuXPnSEtLIy8v75775N3pvZo3b25MnADt27fHYDBw6tQpY/Js0qSJyabZXl5eHDlypNDrpqWl8c4777BmzRri4uLIy8sjMzOT6OhoACIjI7GysqJz5853fH1kZCQdO3Y0Jk5RdekNCq8uOcj1jFya1nZlYo9GANhaaxnQqg4DWtW5xxVERSPJs7g0miI1nVqCUaNG8fLLL/PFF1+wYMEC6tevb0wEs2bN4rPPPuPTTz8lODgYJycnxo0bR05OTqm9/86dOxk6dCjvvvsu4eHhxlraxx9/XGrvcavbk5hGo8FgMBRafsKECaxfv57Zs2fToEEDHBwcGDhwoPEeODg43PX97nVeVB0L//mX3VGJONlaMW9IS+ysre79IlGhyYChSmzQoEFotVoWL17MDz/8wMiRI439nzt27KBv37489dRTNG/enHr16nH69OkiXzsoKIiYmBji4uKMx3bt2mVS5p9//sHPz48333yTkJAQAgICuHDhgkkZW1tb9Hr9Pd/r0KFDpKenG4/t2LEDrVZLo0aNihzz7Xbs2MGIESPo378/wcHBeHp68u+//xrPBwcHYzAY2LJlyx1f36xZM7Zt23bXQUmi8jMYFBbsULcQm9wrCP8aFePLtbg/kjwrMWdnZ5544gkmT55MXFwcI0aMMJ4LCAhg/fr1/PPPP5w4cYLnn3+ehISEIl87LCyMhg0bMnz4cA4dOsS2bdt48803TcoEBAQQHR3NkiVLOHfuHHPnzmXlypUmZerWrUtUVBSRkZFcvXqV7OzsAu81dOhQ7O3tGT58OEePHmXTpk28/PLLPP3008Ym25IICAhgxYoVREZGcujQIZ588kmTmmrdunUZPnw4I0eOZNWqVURFRbF582aWLVsGwNixY0lJSWHw4MHs27ePM2fO8OOPP3Lq1KkSxyQqnu1nr3Lxeiau9tYMlObZKkOSZyU3atQorl+/Tnh4uEn/5FtvvUXLli0JDw+nS5cueHp60q9fvyJfV6vVsnLlSjIzM2nTpg3PPvss06ZNMynz6KOP8tprrzF27FgeeOAB/vnnH6ZMmWJSZsCAAfTo0YOuXbtSs2bNO06XcXR0ZN26dSQmJtK6dWsGDhxI9+7d+fzzz4t3M24zZ84cqlWrRrt27ejTpw/h4eG0bNnSpMxXX33FwIEDeemllwgMDOS5554z1oCrV6/Oxo0bSUtLo3PnzrRq1Ypvv/1W+kCrmJ/3qH3kj7Wsg72NNNdWFRpFKeLkwUosJSUFnU5HcnJygcEsWVlZREVF4e/vj729vZkiFJWB/FuqfC6nZtFu+kbyDAp/jetIoGfxBsMJy3K3XHA7qXkKIUQJ/bL/InkGhZa+bpI4qxhJnkIIUQIGg8KSPTEADGnja+ZoRHmT5CmEECXwz7lrRCdm4GJvzSPNzLTqmDAbSZ5CCFEC+QOF+reojYOtDBSqaiR5FpGMqxL3S/4NVR77LySy7lg8AINbS5NtVSTJ8x7yl3srzZV3RNWUkZEBFFwJSVQskTFJDP/fXvIMCmFBHjT2loFCVZEsz3cP1tbWODo6cuXKFWxsbNBq5fuGKB5FUcjIyODy5cu4ubmZrL8rKpajsck8/d1u0rLzeLCeO/OGtDB3SMJMJHneg0ajwcvLi6ioqAJLywlRHG5ubrLJdwVyOTWLZ7/fR1p2HrXdHPDS2fP38QRSs/II8avGd8NbS19nFSbJswhsbW0JCAiQpltRYjY2NlLjrGDm/H2awxeTATh/5ea6yg/4uLHgmdY42cmfz6pM/u8XkVarlVVhhKgiTieksmyfOodzxoBgrLRa4pIysbHWMqSNLy720m9d1UnyFEKI28xYexKDAj2aePKEjKYVdyCjX4QQ4hY7z10j4uRlrLUa46bWQtxOkqcQQtxgMChMX3sCgCfb+lKvprOZIxKWSpKnEELcsPpIHIcvJuNsZ80r3QPMHY6wYBafPFNTUxk3bhx+fn44ODjQrl079u7dazyvKApTp07Fy8sLBwcHwsLCOHPmjBkjFkJURP9eTeed348B8ELnetRwtjNzRMKSWXzyfPbZZ1m/fj0//vgjR44c4eGHHyYsLIzY2FgAZs6cydy5c5k/fz67d+/GycmJ8PBwsrKyzBy5EKKiSEzPYcSCPSSm59C0tiujOtQzd0jCwln0ZtiZmZm4uLjw22+/0bt3b+PxVq1a0bNnT95//328vb35z3/+w4QJEwBITk7Gw8ODhQsXMnjw4CK9T3E2QBVCVC5ZuXqe/HYXB6KTqO3mwMox7ajlItPSqqJKsxl2Xl4eer2+wPxKBwcHtm/fTlRUFPHx8YSFhRnP6XQ62rZty86dO8s7XCFEBaM3KLy65CAHopPQOdjw/cjWkjhFkVh08nRxcSE0NJT333+fS5cuodfr+emnn9i5cydxcXHEx6u7Gnh4eJi8zsPDw3juTrKzs0lJSTF5CCGqntWHL7HuWAK2Vlq+HRZCg1ou5g5JVBAWnTwBfvzxRxRFoXbt2tjZ2TF37lyGDBlyXwu0T58+HZ1OZ3z4+PiUYsRCiIoif1uxZzv608bf3czRiIrE4pNn/fr12bJlC2lpacTExLBnzx5yc3OpV6+ecZHthIQEk9ckJCTcdQHuyZMnk5ycbHzExMSU6WcQQlie7Dw9W05dASC8iSzYL4rH4pNnPicnJ7y8vLh+/Trr1q2jb9+++Pv74+npSUREhLFcSkoKu3fvJjQ0tNBr2dnZ4erqavIQQlQtu88nkp6jp6aLHcG1deYOR1QwFr+27bp161AUhUaNGnH27Flef/11AgMDeeaZZ9BoNIwbN44PPviAgIAA/P39mTJlCt7e3vTr18/coQshLNiGE2qLVffAWmi1GjNHIyoai0+eycnJTJ48mYsXL+Lu7s6AAQOYNm0aNjbqrgYTJ04kPT2d0aNHk5SURIcOHfjrr79kBxQhRKEURSHixGUAwoI87lFaiIIsep5neZF5nkJULSfiUuj52TbsrLVETn1YNrUWQCWa5ymEEGVhw3G1ybZjQA1JnKJEJHkKIaqcDSfVJtvu0mQrSkiSpxCiSrmcksWhmCRAHSwkRElI8hRCVGpZuXpWHYxl37+JZOXq2Xij1tm8jo5arjKwUJSMxY+2FUKIkjLcWLt23TG1j9PGSoODjdrHKaNsxf2QmqcQotL6ass51h1LwMZKQw1nO3L1CilZeQA8LKsKifsgNU8hRKW06eRlZv99CoD3+jZlcGsfYhIz2R+diJuDLY08ZRF4UXKSPIUQlc6/V9N5ZclBFAWebOvLkDa+APhWd8S3uqOZoxOVgTTbCiEqlcspWTz7wz5Ss/Jo6evG230amzskUQlJzVMIUWlEXU1n2P92E5OYiYerHV891Qo7a1kEQZQ+SZ5CiErhaGwyw/+3h2vpOfhVd+THkW3xkKkoooxI8hRCVHgHoq8z7Ls9pGXn0djLle9HtqGmi525wxKVmCRPIUSFZjAo/N+KI6Rl5/FgPXe+GRaCq72NucMSlZwMGBJCVGh/Ho3jZHwqLnbWzH+qlSROUS4keQohKqw8vYE5608D8GzHerg52po5IlFVSPIUQlRYqyIvcf5KOtUcbRjZoa65wxFViCRPIUSFlJNn4LMItdb5Quf6uEhzrShHkjyFEBXS8v0xxCRmUsPZjmGhdc0djqhiJHkKISqcIxeTmRtxBoCxXevjYCsLIYjyJVNVhBAVxuWULGatO8UvBy6iKODr7siQtr7mDktUQZI8hRAVwurDl5j4y2EycvQA9HvAmzd6Bsnye8IsJHkKISzeldRsJv96hIwcPS183Zj6SGNa+FYzd1iiCpPkKYSweLPWnSQ1O49mdXT8+kI7tFqNuUMSVZwMGBJCWLTImCSW7bsIwNt9mkjiFBZBkqcQwmIZDArv/H4MgMda1qaVnzTVCssgyVMIYbFWHIwlMiYJJ1sr3ugRaO5whDCS5CmEsEhp2XnM+OskAK90D6CW7M0pLIgkTyGERVq6N4YrqdnUre7IM+39zR2OECYkeQohLI7BoPDTrguAuluKrbX8qRKWRf5FCiEszo5zV4m6mo6LnTX9W9Q2dzhCFCDJUwhhcX7YqdY6B7Sqg5OdTEcXlkeSpxDCosQmZRJxIgGApx70M3M0QtyZJE8hhEVZtOsCBgXaN6hOg1rO5g5HiDuS5CmEsBjZeXqW7o0B4OkH65o3GCHuQpKnEMJi/HkkjmvpOXjp7AkLqmXucIQolCRPIYRFSM3K5YtN5wB4so0v1lby50lYLvnXKYQwu5w8Ay/+dICzl9Oo6WLHk7LBtbBwkjyFEGalKApvrDjM9rNXcbS1YsGI1lR3tjN3WELclUUnT71ez5QpU/D398fBwYH69evz/vvvoyiKsYyiKEydOhUvLy8cHBwICwvjzJkzZoxaCFEcn2w4w4oDsVhpNXwxtCVNa+vMHZIQ92TRyXPGjBl89dVXfP7555w4cYIZM2Ywc+ZM5s2bZywzc+ZM5s6dy/z589m9ezdOTk6Eh4eTlZVlxsiFEEURcSKBuRHql90P+jWlayMZJCQqBoteuuOff/6hb9++9O7dG4C6devy888/s2fPHkCtdX766ae89dZb9O3bF4AffvgBDw8PVq1axeDBg80WuxDi7vQGxbhryjPt6zKkjfRziorDomue7dq1IyIigtOnTwNw6NAhtm/fTs+ePQGIiooiPj6esLAw42t0Oh1t27Zl586dZolZCFE0qw9f4nRCGq721owLa2jucIQoFouueb7xxhukpKQQGBiIlZUVer2eadOmMXToUADi4+MB8PDwMHmdh4eH8dydZGdnk52dbXyekpJSBtELIQqTpzfw6Qa1uXZ0p3roHGzMHJEQxWPRNc9ly5axaNEiFi9ezIEDB/j++++ZPXs233///X1dd/r06eh0OuPDx8enlCIWQhTFioOxRF1Nx93JlhGyV6eogCw6eb7++uu88cYbDB48mODgYJ5++mlee+01pk+fDoCnpycACQkJJq9LSEgwnruTyZMnk5ycbHzExMSU3YcQQpjIztPz2Y1a54ud6+Msu6aICsiik2dGRgZarWmIVlZWGAwGAPz9/fH09CQiIsJ4PiUlhd27dxMaGlrode3s7HB1dTV5CCHKx7K9McQmZVLLxU52TREVlkV/5evTpw/Tpk3D19eXJk2acPDgQebMmcPIkSMB0Gg0jBs3jg8++ICAgAD8/f2ZMmUK3t7e9OvXz7zBCyEKSMnKZe7GswCM7dYAB1srM0ckRMlYdPKcN28eU6ZM4aWXXuLy5ct4e3vz/PPPM3XqVGOZiRMnkp6ezujRo0lKSqJDhw789ddf2NvbmzFyIcSdzPrrFFdSs/Gv4cQTrWWsgai4NMqty/VUUSkpKeh0OpKTk6UJV4gyciD6OgO++gdFgcXPtqVdgxrmDkkIE8XJBRbd5ymEqBxy9Qb+b8URFAUGtKwjiVNUeJI8hRBl7rvtUZyMT6Waow1v9g4ydzhC3DdJnkKIMhV9LYNPN6irhL3ZuzHuTrZmjkiI+yfJUwhRZrJy9Yz9+QBZuQYerOfOgJa1zR2SEKVCkqcQokwoisJbq45y+GIybo42zBrYHI1GY+6whCgVkjyFEGXip10X+GX/RbQa+HxIS3zcHc0dkhClRpKnEKLU7f03kXf/OA7AGz0D6RAgo2tF5SLJUwhRqhLTc3hp0QHyDAqPNPPiuY71zB2SEKVOkqcQolRNWXWUK6nZBNRyZubAZtLPKSolSZ5CiFLzx6FLrDkSh5VWwydPPICjrUWvACpEiUnyFEKUisupWUz57SgAY7o2oGltnZkjEqLsSPIUQtw3RVH4vxVHScrIpbGXK2O7NjB3SEKUKUmeQoj79lvkJTacSMDGSsPHg5pjay1/WkTlJv/ChRD3xWBQmBtxBoCxXQMI8pKdiUTlJ8lTCHFftpy+wvmr6bjYWTOqo7+5wxGiXEjyFELcl++2RwHwRGsfnO1kdK2oGiR5CiFK7FR8KtvPXkWrgeHt6po7HCHKjSRPIUSJLdih1jrDm3jK2rWiSpHkKYQokWtp2aw4GAvAyA7S1ymqFkmeQogSWbw7mpw8A83q6Ajxq2bucIQoV5I8hRDFlpWr54ddFwAY2d5f1q8VVY4kTyFEseRvcn0lNRsPVzt6BXuZOyQhyp0kTyFEsdy6yfXHjz8gqwmJKkn+1Qshikw2uRZCJclTCFEkccmZvPiTusl1n+bessm1qNIkeQohiuSd349xNS2bQE8XZgwIlkFCokqT5CmEuKe07Dw2nbwCwMeDmssm16LKk+QphLinLaeukKM34F/Dicaya4oQkjyFEPf29/F4AB5u7CHNtUIgyVMIcQ85eQY2nrwMwMNNPM0cjRCWQZKnEOKudp2/RmpWHjWc7Wjh42bucISwCJI8hRB3ld9k+1BjD7RaabIVAiR5CiHuwmBQWH88AYCHm3iYORohLIckTyFEoQ5dTCIhJRtnO2va1a9u7nCEsBiSPIUQhfr7Rq2zS6Oa2FlbmTkaISyHJE8hRKH+PnZjioqMshXChCRPIcQdnU5I5dyVdGysNHRpVNPc4QhhUSR5CiEKUBSFD9acAKBzw1q42tuYOSIhLIvFJ8+6deui0WgKPMaMGQNAVlYWY8aMoXr16jg7OzNgwAASEhLMHLUQFdsfh+PYevoKttZa/q9XoLnDEcLiWHzy3Lt3L3FxccbH+vXrAXj88ccBeO211/jjjz9Yvnw5W7Zs4dKlSzz22GPmDFmICi05I5f3buzZObZrA+rVdDZzREJYHovfGqFmTdO+lo8++oj69evTuXNnkpOT+e6771i8eDHdunUDYMGCBQQFBbFr1y4efPBBc4QsRIX20V8nuZqWTf2aTjzfWfbsFOJOLL7meaucnBx++uknRo4ciUajYf/+/eTm5hIWFmYsExgYiK+vLzt37jRjpEJUTHv/TeTnPdEAfNg/WKanCFEIi6953mrVqlUkJSUxYsQIAOLj47G1tcXNzc2knIeHB/Hx8YVeJzs7m+zsbOPzlJSUsghXiAohJSuX9ccS+OPwJbafuQrAEyE+tK0niyIIUZgKlTy/++47evbsibe3931dZ/r06bz77rulFJUQFdf+C9d56r+7yczVG4+1rluNyTJISIi7qjDJ88KFC2zYsIEVK1YYj3l6epKTk0NSUpJJ7TMhIQFPz8IndU+ePJnx48cbn6ekpODj41MmcQthyZbtjSEzV4+PuwMDW/rwSHMv6ssAISHuqcIkzwULFlCrVi169+5tPNaqVStsbGyIiIhgwIABAJw6dYro6GhCQ0MLvZadnR12dnZlHrMQlsxgUIi4sU/n9P7N6BBQw8wRCVFxVIjkaTAYWLBgAcOHD8fa+mbIOp2OUaNGMX78eNzd3XF1deXll18mNDRURtoKcQ+HLiZxNS0bFztr2vi7mzscISqUCpE8N2zYQHR0NCNHjixw7pNPPkGr1TJgwACys7MJDw/nyy+/NEOUQlQsESfUWmenRjWxta5QA++FMDuNoiiKuYMwt5SUFHQ6HcnJybi6upo7HCHKRY9Pt3IyPpVPnmhO/xZ1zB2OEGZXnFwgXzeFqIJiEjM4GZ+KVgNdGtYydzhCVDiSPIWogiJOqOs/h9R1p5qTrZmjEaLikeQpRBWUP8o2LEhqnUKUhCRPIaqY1Kxcdp2/BkBYkIeZoxGiYpLkKUQVs/X0VXL1CvVqOMmOKUKUkCRPIaqYDTf6O8MaS61TiJKqEPM8hRD37/ilFL7Zeo4/DscB0D1Q+juFKClJnkJUcrFJmbzx62G23dgxBeCRZl6E1JVVhYQoKUmeQlRiiqLwn2WR7DqfiFYDvZt581xHf5rVcTN3aEJUaJI8hajE/jwSz67zidjbaPljbAcCPFzMHZIQlYIMGBKiksrM0TNtzXEAXuhcXxKnEKVIkqcQldRXW85xKTmL2m4OvNC5vrnDEaJSkeQpRCUUk5jB11vOAfBW7yDsbazMHJEQlYskTyEqoQ//PEF2noHQetXp0dTT3OEIUelI8hSikjl3JY21R+PRauDtRxuj0WjMHZIQlU6JkueAAQOYMWNGgeMzZ87k8ccfv++ghBAlt/qQughCp4Y1CfSU/WmFKAslSp5bt26lV69eBY737NmTrVu33ndQQoiSW3PkEgC9g73MHIkQlVeJkmdaWhq2tgX3ALSxsSElJeW+gxJClMzphFROJ6RhY6Xh4SbS1ylEWSlR8gwODmbp0qUFji9ZsoTGjRvfd1BCiJJZfWPd2k4BNdE52Jg5GiEqrxKtMDRlyhQee+wxzp07R7du3QCIiIjg559/Zvny5aUaoBCiaBRFYc3hG022zaTJVoiyVKLk2adPH1atWsWHH37IL7/8goODA82aNWPDhg107ty5tGMUQhTByfhUzl1Jx9Zay0Oy3ZgQZarEa9v27t2b3r17l2YsQoj7sOZGk23nhjVxsZcmWyHKUon6PPfu3cvu3bsLHN+9ezf79u2776CEEMWjKAprjqjJ8xFpshWizJUoeY4ZM4aYmJgCx2NjYxkzZsx9ByWEuDtFUdh1/hqrD1/iQPR1tp+9StTVdOystXQPkiZbIcpaiZptjx8/TsuWLQscb9GiBcePH7/voIQQhTMYFD5Yc4L/7YgqcK5ro1o428lOg0KUtRLVPO3s7EhISChwPC4uDmtr+cUVoqzk5BkYvyzSmDib+7hR280BK60GK62Gp0P9zByhEFVDiTLdww8/zOTJk/ntt9/Q6XQAJCUl8X//93889NBDpRqgEEKVkZPHCz8dYOvpK1hrNcx6vBn9W9QBQG9QyNUbZPcUIcpJiZLn7Nmz6dSpE35+frRo0QKAyMhIPDw8+PHHH0s1QCGE6vVfDrP19BXsbbR89VQrujaqZTyn1jwlcQpRXkqUPGvXrs3hw4dZtGgRhw4dwsHBgWeeeYYhQ4ZgYyND5IUobZeSMll7YzTt98+0oW296maOSIiqrcQdlE5OTnTo0AFfX19ycnIAWLt2LQCPPvpo6UQnhABg2b4YDAq09XeXxCmEBShR8jx//jz9+/fnyJEjaDQaFEUx2TNQr9eXWoBCVHV6g8LSverUsCfb+po5GiEElHC07auvvoq/vz+XL1/G0dGRo0ePsmXLFkJCQti8eXMphyhE1bbl9GXikrNwc7QhXHZKEcIilKjmuXPnTjZu3EiNGjXQarVYWVnRoUMHpk+fziuvvMLBgwdLO04hqqzFu9Va54CWdWQ0rRAWokQ1T71ej4uLCwA1atTg0iV1Jwc/Pz9OnTpVetEJUcXFJ2ex8aQ6p3pIGx8zRyOEyFeimmfTpk05dOgQ/v7+tG3blpkzZ2Jra8s333xDvXr1SjtGIaqs/IFCbeq606CWi7nDEULcUKLk+dZbb5Geng7Ae++9xyOPPELHjh2pXr36HTfJFkIUnwwUEsJylSh5hoeHG39u0KABJ0+eJDExkWrVqpmMuhVClNz2s1eJTcpE52BDj6YyUEgIS1JqC9G6u7uX1qWEEMCfh29uMSYDhYSwLCUaMFSeYmNjeeqpp6hevToODg4EBweb7BmqKApTp07Fy8sLBwcHwsLCOHPmjBkjFuL+5ekN/H08HoBewbI/pxCWxqKT5/Xr12nfvj02NjasXbuW48eP8/HHH1OtWjVjmZkzZzJ37lzmz5/P7t27cXJyIjw8nKysLDNGLsT92ROVyPWMXKo52tDWX1p1hLA0Fr1/2IwZM/Dx8WHBggXGY/7+/safFUXh008/5a233qJv374A/PDDD3h4eLBq1SoGDx5c7jELURrWHlVrnQ839sTayqK/4wpRJVn0b+Xvv/9OSEgIjz/+OLVq1aJFixZ8++23xvNRUVHEx8cTFhZmPKbT6Wjbti07d+40R8hC3DeDQeGvY2ry7BEsA4WEsEQWnTzPnz/PV199RUBAAOvWrePFF1/klVde4fvvvwcgPl79A+Ph4WHyOg8PD+O5O8nOziYlJcXkIYSl2B99nSup2bjYW9O+fg1zhyOEuAOLbrY1GAyEhITw4YcfAtCiRQuOHj3K/PnzGT58eImvO336dN59993SClOIUrX2iPrFLyzIA1tri/5+K0SVZdG/mV5eXjRu3NjkWFBQENHR0QB4eqpNWgkJCSZlEhISjOfuZPLkySQnJxsfMTExpRy5ECWjKArr8ptsZW6nEBbLopNn+/btC6yVe/r0afz8/AB18JCnpycRERHG8ykpKezevZvQ0NBCr2tnZ4erq6vJQwhLcPhiMrFJmTjaWtG5YU1zhyOEKIRFN9u+9tprtGvXjg8//JBBgwaxZ88evvnmG7755hsANBoN48aN44MPPiAgIAB/f3+mTJmCt7c3/fr1M2/wQpRA/ijbro1qycIIQlgwi06erVu3ZuXKlUyePJn33nsPf39/Pv30U4YOHWosM3HiRNLT0xk9ejRJSUl06NCBv/76C3t7ezNGLkTJ/H2jybanjLIVwqJpFEVRzB2EuaWkpKDT6UhOTpYmXGE2MYkZdJy5CWuthoNTH8LF3sbcIQlRpRQnF1h0n6cQVcnWM1cAaOlbTRKnEBZOkqcQFmLb6asAdAyQuZ1CWDpJnkJYgDy9gR3nbiRPGWUrhMWT5CmEBTh0MYnUrDzcHG0Irq0zdzhCiHuQ5CmEBdh6o8m2fYMaWGllQ3khLJ0kTyEswLYbg4U6SX+nEBWCJE8hzCw5M5fImCQAOgRIf6cQFYEkTyHKkaIojFl8gEHzd3I1LRuAf85exaBA/ZpO1HZzMHOEQoiikOQpRDmKT8lizeE49vybyFP/3U1ieg5bz6j9nZ1klK0QFYZFL88nRGVz+GKy8eeT8ak89d/dJGXkANBJmmyFqDAkeQpRjg5fTAKgXf3qnE5I5XicuhG7jZWGtvXczRiZEKI4pNlWiHKUX/PsFezFomcfpJqjugxfiJ87jrbyXVaIikKSpxDlRFEUjsSqybNZHR2NPF1Y/NyDPNzYg3FhAWaOTghRHPJVV4hycvF6JkkZudhaaWnk6QJAkJcr3wwLMXNkQojikpqnEOUkv8k20MsFO2vZ6FqIikySpxDlJH+wkKxdK0TFJ8lTiHKSX/NsVkeSpxAVnSRPIcqBwaBw9MZgoeDabuYNRghx3yR5ClEO/r2WTmp2HnbWWhp6OJs7HCHEfZLkKUQ5yG+ybeLtirWV/NoJUdHJb7EQ5eBmf6ebeQMRQpQKSZ5ClIMjsUmAjLQVorKQ5ClEGdMbFI7GqmvYykhbISoHSZ5ClLGzl9PIzNXjZGtFvZoyWEiIykCSpxClJCtXf8fj+YsjNKmtw0qrKceIhBBlRZKnEPdJURQm/nKIxlP/4p+zVwuc33U+EYBm0t8pRKUhyVOI+zRr3SmW7buIQYHvtkeZnMvM0fPX0TgAwpt6miM8IUQZkOQpxH1YtPsCX24+Z3y++fQVLqdkGZ//fTye9Bw9Pu4OhPhVM0eIQogyIMlTiBLaeDKBKauOAjAuLICWvm7oDQorDsYay/x6QP25f4s6aDTS3ylEZSHJU4gSuJSUyZhFBzEoMCikDq92D2BQiA8Ay/fFoCgKl1Oy2H7mCgCPtahtznCFEKVMkqcQJbAqMpbMXD3NfdyY1j8YjUZD72Ze2NtoOXclnQPRSfwWeQmDAi193ahbw8ncIQshSpEkTyFKYM1hdRDQ4NY+2NxYq9bF3oZewV4A/LI/hl8PXATgsZZ1zBOkEKLMSPIUopiirqZz7FIKVloNPZqYjqDNb7r9dX8sJ+NTsbXS8kgzL3OEKYQoQ5I8hSimNYcvAdC+QQ2qOdmanGvr746vuyM5egMA3QJr4eZoW+AaQoiKTZKnEMW0+kaT7Z1qlBqNhsdb3WymfaylDBQSojKS5ClEMZy9nMrJ+FRsrDSEN77zogcDWtXB0dYKb509XRrVKucIhRDlwdrcAQhRkeTXOjs0qIHO0eaOZbzdHFg3rhN21lpsreX7qRCVkSRPIYphjbHJ1vuu5XzcHcsjHCGEmVj01+J33nkHjUZj8ggMDDSez8rKYsyYMVSvXh1nZ2cGDBhAQkKCGSMWldnphFTOXE7D1krLQ008zB2OEMKMLDp5AjRp0oS4uDjjY/v27cZzr732Gn/88QfLly9ny5YtXLp0iccee8yM0YrKbPUhdZRtp4Y1cbW/c5OtEKJqsPhmW2trazw9Cw7MSE5O5rvvvmPx4sV069YNgAULFhAUFMSuXbt48MEHyztUUYnt+zeR/97YMUXmbQohLL7meebMGby9valXrx5Dhw4lOjoagP3795Obm0tYWJixbGBgIL6+vuzcudNc4YpK6GD0dUYs2EtGjp4ODWrQW5KnEFWeRdc827Zty8KFC2nUqBFxcXG8++67dOzYkaNHjxIfH4+trS1ubm4mr/Hw8CA+Pv6u183OziY7O9v4PCUlpSzCF5XA0dhkhv1vD2nZeTxYz51vh4UYl+MTQlRdFp08e/bsafy5WbNmtG3bFj8/P5YtW4aDg0OJrzt9+nTefffd0ghRVGIXr2fw1He7Sc3KI8SvGt8Nb42DrZW5wxJCWIAK9RXazc2Nhg0bcvbsWTw9PcnJySEpKcmkTEJCwh37SG81efJkkpOTjY+YmJgyjFpUVL/sv0hSRi6NvVxZ8ExrnOws+rumEKIcVajkmZaWxrlz5/Dy8qJVq1bY2NgQERFhPH/q1Cmio6MJDQ2963Xs7OxwdXU1eQhxu4gTlwEY0b4uLjK6VghxC4v+Kj1hwgT69OmDn58fly5d4u2338bKyoohQ4ag0+kYNWoU48ePx93dHVdXV15++WVCQ0NlpK24b/HJWRyJTUajURd3F0KIW1l08rx48SJDhgzh2rVr1KxZkw4dOrBr1y5q1qwJwCeffIJWq2XAgAFkZ2cTHh7Ol19+aeaoRWUQcVJdbKOFjxs1nO3MHI0QwtJoFEVRzB2EuaWkpKDT6UhOTpYmXAHAMwv2sOnUFV4Pb8SYrg3MHY4QohwUJxdUqD5PIcpDRk4eO85dA+ChxrIMnxCiIEmeQtxm25mr5OQZ8HF3IKCWs7nDEUJYIEmeQtwm4oTa3xkW5IFGozFzNEIISyTJU4hbGAwKG0+qU1TCgqTJVghxZ5I8hbhF5MUkrqbl4GJvTRt/d3OHI4SwUBY9VUWIspaRk8fi3dHY2VjhrbNnw40m284Na8oatkKIQknyFFXax3+f5rsbW43dSppshRB3I8lTVFlJGTn8vEfd4q59g+okZeQSl5yFh6s93YNkVSEhROEkeYoq66ddF8jI0RPk5cpPo9rKyFohRJFJp46okrJy9SzY8S8AL3SuJ4lTCFEskjxFlfTL/otcS8+htpsDvYO9zB2OEKKCkeQpqhy9QeHbbecBeK6jP9YyqlYIUUzyV0NUOeuOxXPhWgZujjYMau1j7nCEEBWQDBgSld6+fxP5aO1JsvMMAFy8ngHAsNC6ONrKr4AQovjkL4eo9D6LOMO+C9dNjrnYWTM81M9MEQkhKjpJnqJSS8rIYeeN7cU+feIBdI42ADSo6Ux12eRaCFFCkjxFpbb+eAJ5BoVATxf6taht7nCEEJWEDBgSldrao/EA9GjqaeZIhBCViSRPUWmlZuWy/cxVAHrJXE4hRCmS5CkqrY0nL5OjN1CvphMBtZzNHY4QohKR5CkqrbVH1Cbbnk09Zfk9IUSpkuQpKqWMnDw2n74MQM+m0mQrhChdkjxFpbT51BWycg3UqeZAE29Xc4cjhKhkJHmKSil/lK002QohyoIkT1HpZOXq2XgiAYCeMspWCFEGJHmKSmflwVjSc/TUdnPggTpu5g5HCFEJSfIUlYreoPDtVnW7sWfa10WrlSZbIUTpk+QpKpX1xxM4fzUdnYMNQ9r4mjscIUQlJclTVBqKojB/yzkAnn7QDyc7WbpZCFE2JHmKSmPvv9eJjEnC1lrL8HZ1zR2OEKISk+QpKo2vb9Q6B7aqQ00X2W5MCFF2JHmKSuF0QioRJy+j0cBzHeuZOxwhRCUnyVNUCl9sOguoiyL413AyczRCiMpOkqeo8PZfSOS3yEtoNPBSlwbmDkcIUQVI8hQVmsGg8M7vxwEY1MqHprV1Zo5ICFEVSPIUFdry/TEciU3Gxc6a13s0Mnc4QogqQpKnqLCSM3OZ+dcpAF4NC6CGs4ywFUKUD0meosL6bMMZrqXn0KCWs8zrFEKUqwqVPD/66CM0Gg3jxo0zHsvKymLMmDFUr14dZ2dnBgwYQEJCgvmCFOUiJjGD73f+C8DbfRpjY1Wh/ikLISq4CvMXZ+/evXz99dc0a9bM5Phrr73GH3/8wfLly9myZQuXLl3iscceM1OUorzsOHsVvUEhxK8aHQNqmjscIUQVUyGSZ1paGkOHDuXbb7+lWrVqxuPJycl89913zJkzh27dutGqVSsWLFjAP//8w65du8wYsShrhy8m8Yh2Jw97JJk7FCFEFVQhkueYMWPo3bs3YWFhJsf3799Pbm6uyfHAwEB8fX3ZuXNneYcpypH+33/43HYezxx/DuIOmzscIUQVY/HbTixZsoQDBw6wd+/eAufi4+OxtbXFzc3N5LiHhwfx8fGFXjM7O5vs7Gzj85SUlFKLV5S97Dw9Na4fBCuwyUuDnwbAqL/B3d/coQkhqgiLrnnGxMTw6quvsmjRIuzt7UvtutOnT0en0xkfPj4+pXZtUfZOxafSBHXDa0VrDemX4cf+kHbZzJEJIaoKi06e+/fv5/Lly7Rs2RJra2usra3ZsmULc+fOxdraGg8PD3JyckhKSjJ5XUJCAp6enoVed/LkySQnJxsfMTExZfxJRGk6dDGZYE0UAJr+X4ObL1yPgkUDITvNzNEJIaoCi06e3bt358iRI0RGRhofISEhDB061PizjY0NERERxtecOnWK6OhoQkNDC72unZ0drq6uJg9RcZz79198tFfUJwEPwdOrwLEGxB2Cff8za2xCiKrBovs8XVxcaNq0qckxJycnqlevbjw+atQoxo8fj7u7O66urrz88suEhoby4IMPmiNkUQ5yYw4CkO5cFyd7HdjroNubsPo1OLwU2r9i5giFEJWdRdc8i+KTTz7hkUceYcCAAXTq1AlPT09WrFhh7rBEGcnM0VMtWV0IXlu7xc0TTfqDlS0kHIX4o2aKTghRVVh0zfNONm/ebPLc3t6eL774gi+++MI8AYlydTwuhaYadbCQvV+rmyccqkHDcDjxBxxeAp4fmClCIURVUOFrnqJqOXwxiWCtmjw13i1NTzYbrP73yC9g0JdzZEKIqkSSp6hQov79l9qaayhowMt0qUYCHlZroKlxELXFPAEKIaoESZ6iQsm9qA4WynD1BzsX05PWttDkxrrGh5eVc2Tl4PxmWDsJUgtfAEQIUT4keYoKIy07jxqp6mAhq1sHC92q+Y2m2+O/Q056OUVWDlLjYclTsHs+fNMVYg+YOyIhqjRJnqLCOBabTHD+YCHfkDsXqtMa3OtBbjqcXFOO0ZWxv9+CnFT159RLsKAnHP3VvDEJUYVJ8hQVxuGLyQRr1ZWF8C6k5qnRQLMn1J/3LwR9XrnEdlfxR2HZMLhyumSvj9oKR5YDGhj+h9q3m5cFv4yEX5+DoysgI7FUQxZC3J0kT1FhRF04j5cmUR0s5BlceMFmT4DWGi7sUJfsy7xefkHeTlHgt5fg+G+w4e3Cy6VdUftpV76gJsS4Q+rxvBxYM0H9ufUo8O8EQ5ZAu5fVY0eWwS/PwMx68N3D0pwrRDmpcPM8RdV0JiGVa6d3gxVk6hrgaOdceGF3f3h8IawYDec3wbfd4cmlUCOg9AJKioF1/6euq9vxP+DofudyJ36/mQhP/wXJsaCrffN8YhSseA4u3rZr0JHl6pcA51pw9ZS6/GC3t9RzWit4+ANo1AtOrIZzG+HKCYjZrTbn9v0CggeqZQ16OPiTGkeNhlC/G/i1A1un0rsXQlRBGkVRFHMHYW4pKSnodDqSk5NlnVsLlJWrp+/nO+hxdSGv2fyK0mwwmse+vvcL4w7DkichOQbsdPDw+9DiKTX53I/o3bB0KKTfWF/XTgcdx0PbF8Dmlt1/DHr4qh1cOanWhA150PkN6Dr5ZplFj8OZv9WfPZupyS35Ihz9xfQ9+34JLYYWHlPyRVg9Hs6sU593/A/4tIX1b6uJ9VZWthD0KDz2zf3fCyEqkeLkAmm2FRbv/dXHOZWQyoO2ZwHQFNbfeTuvZvDcJvB5ELKT4Y9X4Kv2cPpvtTm1JA4ugu8fUROnR1PwCFavveFt+Lw1RO+6WfbIL2ritHeDnjPUYwd+uNkPG71bTZwaK3hpF7ywDR56FwZ+p8bt10EtV7cjNB9y97h0dWDIz9Duxrq+2z6GxYPUxGnvBl0mQ8vhoPMBfY6anGUurBAlJslTWLS1R+JYtDuaZ63WEKrcaP6s26HoF3CuqQ6yCf9QTSJXTsDix2H5CDAYihfM1tlq/6U+B4L6wMh18PwW6PcVuNaG5GhY+Agc+BH0ubD5Q/V17V+BFk+DY3V1pOyZG8l74/vq+RZPQa0g0/eq3RJGrFaT6tDloC3Cr6rWSq1d95uv1i6tbNW+0Vcjocsb8OhcGHcEWo1Qyx9aWrzPL4QwkmZbpNnWUl1KyqTHp1sJy9nIHNv56sGwd6HDuJJdMPM6bJsDu74CQy48s1bt/yuKhGMwvyMoeug0Ua3J3ZrQctJh1YvqwCBQa7sxu8CpJrx6SO1j/Pst+GeeOlr2wZfgx35qgnv5ALiV8obsybFgZaP2md4uZg989xDYOMHrZ6T/U4gbipMLZMCQsFhz1p+mZc5eZtl+ox4IHQvtXy35BR2qqTWzjESI/AkOLSla8lQUWPMfNXEGPapuf3Y7WycYuBC2zoTN09XECWrfY35yavWMmjzPrIfrF9RjISNLP3GC6aCk2+XPhU08rw44av5E6b+/sEyKog50i9oGddvfGEDWHpKi1YFn5zZCSiz4Pqie8++kfuk8GwHnNqmD35Rb1o12rQ31u0L97ur0sbhD6jXObwJrO+g4Aep1Nt/nLUNS80Rqnpbo3JU0xnzyEytspuKoyVZHnvabX7Tmy3uJ2grf91EH+kw4bTrI504iF6u1ShsnGLtH7V+8m2OrYNVLalIcvcX0+t8/erOv0cZRrZXeqXZY1jZ/pCb5+t3g6ZXl//7CPA78CL+Pve2gBiiNNFDIdQIehofeK9g1YYGk5ikqvE83nOF1qyVq4qzXRZ1+URqJE9SBOK611W/Yp/+CJv0KL5t5Hf6eov7ceeK9Eyeo1wt4WP359sQc8szN5Nn2efMkToBmg9TkeX6zuvSfi6d54hDl58ppWDtR/bnVM4ACZzeqffXW9moNtEF3qFZXrZmei4Crp9WR4j4PqjXMuh3AxkG9hmJQuzPObVRrpZmJ6riC+l2hXld1b919/1P7+M+sB/tbkpHOF/rOM13sRJ8L66eq2wr6tFVjqd9NbSk6F3FjStYp9TX556rVLZ97dweSPIXFORGXQuzhzXS3O4iisULTe47af1datFoIfhx2fAqHl949eW78ADKuQo1Gaj9lUdk63vl4o97qtXLSbo6MNQf3euofqJjd6pzS/EUXROWUe2NFqtwM8O8MveeovweKou5C5FDtZlIECOyt/jc1Qf23fPsmDPm8W6gD3gx69cuoa23T6U9tnoeId9SEmJV883jWEfhfT+j3BTQdoCbIZcPg323q+eSYgtO18qXEwsnV6s82jqg13htaDYce04tzZ0pMkqewOJ+sP80Ea3VXFE2LoVC9fum/SfPBavI88zekXwOn6gXL/Lsd9n6n/tz7Y3XXlvtlbatOSTHoC0+w5aXZE2ryPLS0aMlz62zY/z30mgmNepZ9fKL0bHgHEo6oI777f32zFUejAVfvwl/n4lG062ut1AVDblejATzxk9q6kZ2mHjPkwfop6u/eLyMhZq/aAnQ9Cmyd1SbelEtqbfNSpNp3ml8r9miqDng7F6H+NzfD9P30OUWLtxRInyfS52lJDl9M4qMvv2ax7YcoWls0r5TBSNR88ztC/GHoNRvaPGd6Lv4oLOilzuFsNhiKsihDRZORCB83Uv/gvPgPeDQpvGxWCnwcqC64jwbC3ob249Q/vqJ0KUrx7mtqgjot6thKaDpQnZaU3x2QmQTbZqsD1QCeXAYNw0s95GIz6NW50flxgZp8hywx/XeYlQxWdncel5CdChnXTI/Zutz5i3ARSZ+nqJD0BoWP/jzB6/m1zpBnyi5xglr7jD+sjrq9NXlevwA/DVATp28o9Pm07GIwJ0d3tW/25GrY9aXar1yYI8vVxGntAHmZak3m8gnoM/feA64qo5wMWNgL3Pxg0Pf3Ll+UhJidCr+NhQv/QJ/PILDXzXN5OfDXJIj8GeqE3BgJ21mtvf0z78aXGmDfd2pXRPtX1Vrc1pk313Zu97JlJE64ucRkrcbqSPY6ITBwATjVMC1nryv8GnYuhTcnlwOpeSI1T0vx3h/HubDzF76z/RiDtT3aVw8XvdmoJFITYE6gOvDhhe3qH8KsZHX+5bWz6i/2M3+q/UGV1blN6ucFtbnsTlOBFEWtpSccgfDpav/z2knqlIV6XeDpVfdODAZD6Q34upNDS+DPifD4ArV5rzCKAkuGqusFj/z7zrWUoiS6Mxtg0QD15zF7oGajwsue+EMdfV2vM3R/R23KvF1iFPw85JalFDXQfQp0GK/WrpY+DdH/FP4edVqrg4D2/hcu3bY5QM1A9f9twMOW2VKQl1M6XSKlQGqeomJJucTWv5bS4shfjLM5DIC27QtlmzhBvX79bnB2A8y/bdUinS889WvlTpygjox8+AN1AYf1U9VFHR540rRM7H41cVrZqbV1R3d1kfmfB6ujdQ/9XPA1tzq2Ela/pg6Q6ji+bD7Hri9vLJP4jvr/tLAkEXsATt3Y53XHJ+pnv9WK59V9Un0fvDl/0bNZwcR/YcfNn4//po7EvpPr/6qJMztFTaKn1qpze9u9rNYMQZ0b+ctIdbSqs6eaZA8vhYj31D6/S5HqiFg7V7XvPStZHXkatU0dJd3tTWjcT/3MzYfAsRXq6lV52WoT7gNPgZUF/6m3kMRZXFLzRGqeZnX8d5Rlw9DcOj+sRkN16bvCdiopTec2qt/487JuHnOvp/YNleYuLJYuf/UjjZW6Ru6tzXurxqiLStze97v9U7XfyrEGvLzvzl800q/B561uNh32nqNurVaakmPhk8Y3nw/7vfCJ+b+NUXeZAXV6xiuR4OqlPj+1Vv1CcLvgQTDgW9Nj34XfXAijVhN46Q61Qn2uusvNxb1QO0QdrJO/cP+deLeAwYvVATx7v1OnlRhurIPsXk/tD7y1hnu3GrKiqI+yrO1XQrIwvKgwUnd8gwaFU4Y6bPYYjvLMWnXwSnkkTlBrKZNj4a3LNx9j91etxAkQ9p5aa1H0sGz4zWUGM5PUmhioc1Rv9eBL6rSbjKvqlJ47iXhHTZy2N/qm1vxHXUSiNJ3+y/T5rYNQbpWZBEdufBbX2uoXpm2z1ec5GTfnQIaMVAeRNbrR53hshek0i9xMtTYOgAYuH4OrZwq+3+bpauK006nNyUOXqess125lWk6jVe/9iD9vjnxtPUpdvELnAw17wLMRBZuG79YEq9FI4ixjcneF+aRfwzFWbf5a4DONjs9/hsavXenO6SwKK2t1OHz+oyr+0dFq4dF50LCnOiBo2TDYPENtPszLhJpB6rzQW1nbqs2IoNaULh00PR+zV91FBtTF7VuNABR1/9KoraUXe37ybDlMTURn10PC8YLlDi+7+Vn636hB7/9eHSC2fY66RJ1rHbUpt81zag28RiO19nd2w83rXNynro3s4qV++QI4vsr0vc5vUddRBnj0s5vTOPw7wXMbYer1m48p16D//IJTl/w7qQv5P7m0/L5MiiKrgn8lhKW4vG8FVhg4ZvDjhf4PYaW1wMEMVYmVjTonL38xiM0fwrob6/iGjLxzTce/o7rgBDfW/83fqcaghzU3+jcfGAp+oWqTbVAfdWrM94/CN10h4n11dGlhO9xkp6nXKkxOupqoQI076FH1552fm5ZTFNi/4MZneUaNu14XNQmuHgc7PlPP9ZhuulB+/nzWU2tvHrtwo4nWr93NBTbya+qgNlWvfF69Jy2HQZP+BePWak0fhbHEAT4CkOQpzCh533IATlfvTt0asrOHRbCyVhPIo/NAa6MmF2sHdTm/wjz8gTqYJXa/2ve46iX483V1GpC9Tt0JB9TpCY/9V11lCUUdFbptttovuG5ywetePgGzG8LcB+Dw8jsn2HObQJ+tjpSuGXhzsYfDyyAl7ma5mN1w+fiNz3JjIfxuU29cY6Oa0BuEqcn9VvnJ88zfah8m3Bws5NcOAh9R+4njj8C1c2qS/u0lddWeGg2hx0eF3zdRoUnyFGaRfC2Buin7APDrdJeRmsI8Wg6D4b+rg2E6TwQHt8LLunjCI5+oS6WlxkHkInW+IUD3qeqeqvls7GHIYhh/Evp+eTNZHVyk9jveat8Cdf5iUjSseBb+201d9elW+TXCRr3UWlqdEPBtpyb93fNNrwXqUnD5n6VOq5v9mlZ20HNmwZpendbqQJ+sZHWj87wcdWUbUFe9cXRXm1dBrX3u+UZtRrayhYH/k+3eKjFJnsIsDqxfhI1GT5S2Li0eCDF3OOJO/Nqpo0iLMr0keCBMjFLnfLZ7BbyaQ5PHbixAfgeuXtBiKDz+gzotKCcVTv1587w+9+ZApeDH1Wkdlw7Cwt6w58bIV4P+Zn9nox43X5tf+9zxKXwZCn/9nzpdBgoOenrofXUqSo/pd14GUmsFATdGHp9aq04rycsEB3e1PxRuNt3uW6COWga1Nu4ZfJcbJio6C578IyqrXL0Bu9N/AJDe4BE00q9TOdjY35gb2bXor9Fq1SbhbbPVwUnBA9XjZyPUUbxONdWt6DITYcO76pSZP19Xa4O6OmoZO51aC8zXsIc6veTIcrWp9vKNwUMewQVHutZooK41fDeNesChxWpyz69F+7W72VcZ+AisHq/Oxcx//zaji34PRIUkNU9R7jYePEWI/hAAAV2HmjkaYXbNb8ytPBsBaZfVnw8vUf/bdKDaD+tcC/p+DiGjUEfsjoZN09QyDbqbjtDWatV5mRPPq02nLZ5S51A+/F7JBuDU76Y2w16PujlH9NZN1J1qqFt1gbrIQd8vZaBPFSDJU5S7U1uWYavRc9WxHnZeje/9AlG51QgA75bqHNOjv6r9iydvNOE2f+JmOY0Ges2Cxn3VPs3zm9Xj+f2Wt3N0V/s4+34BozffnFZSXHYuULej+vO1s+p/b02eAJ0nqX2tT/x4XwuTi4pDkqcoV2fikmiWFAGAffMBZo5GWIz82uehJerAG3222qfo9YBpOa0VPPbtzWSmsYKAsLKP79Yt2Gxd1CbgW9VtDyPXgk+bso9FWARJnqLspVxSm7uWP0Od75rRxUptsnVuIclT3NB0AGitIS7y5uICzZ+4c/OntZ26jF3w4+ri6eWx/nDDWwYk+ba17LViRbmQfwGl5fxmdX9EoVIM6ujIsxG37BQBDkCq4kBCvQE0qBVkvviEZXGqoc6zzN8UGdRBP4Wxd4UB/y2f2EDdGs8jWF0g//YmW1ElSfIsLRunwcU95o7CQmnAuwVXPTvywk4dx7UN2fVEj3u/TFQtzZ64OfWkbsey3cu1JHpMhwPfFz79RlQpkjxLi1dztTlJ3FStrjpIo14XcHTn+79PsU85S1hDD1zty3n9WmH5GvVUVyrKTrm5CpAl8e+oPoRAkmfp6T3b3BFYNEVRWHNYXS6tT3MvM0cjLJKNg7osYPTOuy8HKIQFkOQpysWJuFTOX03HzlpL96Ay3uRaVFxN+t1csUcIC2bRo22/+uormjVrhqurK66uroSGhrJ27c3dDbKyshgzZgzVq1fH2dmZAQMGkJCQYMaIRWFWH74EQNdGtXC2k+9sQoiKzaKTZ506dfjoo4/Yv38/+/bto1u3bvTt25djx44B8Nprr/HHH3+wfPlytmzZwqVLl3jsscfMHLW4naIorDmiNtn2biZNtkKIik+jKIpi7iCKw93dnVmzZjFw4EBq1qzJ4sWLGThQXQ/z5MmTBAUFsXPnTh588MEiXzMlJQWdTkdycjKurq5lFXqVdeRiMn0+3469jZb9bz2Ek9Q8hRAWqDi5wKJrnrfS6/UsWbKE9PR0QkND2b9/P7m5uYSF3VxdJDAwEF9fX3bu3GnGSMXt8ptsuwd6SOIUQlQKFv+X7MiRI4SGhpKVlYWzszMrV66kcePGREZGYmtri5ubm0l5Dw8P4uPj73rN7OxssrOzjc9TUlLKInQB5OkNrDgYC0Cf5t5mjkYIIUqHxdc8GzVqRGRkJLt37+bFF19k+PDhHD9+/L6uOX36dHQ6nfHh42Nhk7ErkS2nr3AlNZvqTrZ0C6xl7nCEEKJUWHzytLW1pUGDBrRq1Yrp06fTvHlzPvvsMzw9PcnJySEpKcmkfEJCAp6enne95uTJk0lOTjY+YmJiyvATVG3L9qn3tl+L2thaW/w/NyGEKJIK99fMYDCQnZ1Nq1atsLGxISIiwnju1KlTREdHExoaetdr2NnZGae/5D9E6buWlk3ECXV/xkEhUrsXQlQeFt3nOXnyZHr27Imvry+pqaksXryYzZs3s27dOnQ6HaNGjWL8+PG4u7vj6urKyy+/TGhoaLFG2oqys/JgLHkGheZ1dDTydDF3OEIIUWosOnlevnyZYcOGERcXh06no1mzZqxbt46HHnoIgE8++QStVsuAAQPIzs4mPDycL7/80sxRC1Dndi7fdxGAgVLrFEJUMhVunmdZkHmepe/wxSQe/XwHdtZa9rwZhs5BFoIXQli2SjnPU1Qs+QOFejT1lMQphKh0LLrZtiJ5bWkkJ+Jkvmi+81fTARkoJISonCR5lpIL19I5GZ9q7jAsSr2aToTWq27uMIQQotRJ8iwlb/dpQmpWnrnDsChNvF3RajXmDkMIIUqdJM9S0tzHzdwhCCGEKCcyYEgIIYQoJkmeQgghRDFJ8hRCCCGKSZKnEEIIUUySPIUQQohikuQphBBCFJMkTyGEEKKYJHkKIYQQxSTJUwghhCgmSZ5CCCFEMUnyFEIIIYpJkqcQQghRTJI8hRBCiGKS5CmEEEIUk2xJBiiKAkBKSoqZIxFCCGEu+TkgPyfcjSRPIDU1FQAfHx8zRyKEEMLcUlNT0el0dy2jUYqSYis5g8HApUuXcHFxQaPRlOgaKSkp+Pj4EBMTg6uraylHWLHJvbk7uT+Fk3tTOLk3hSvpvVEUhdTUVLy9vdFq796rKTVPQKvVUqdOnVK5lqurq/xDLoTcm7uT+1M4uTeFk3tTuJLcm3vVOPPJgCEhhBCimCR5CiGEEMUkybOU2NnZ8fbbb2NnZ2fuUCyO3Ju7k/tTOLk3hZN7U7jyuDcyYEgIIYQoJql5CiGEEMUkyVMIIYQoJkmeQgghRDFJ8hRCCCGKSZJnKfniiy+oW7cu9vb2tG3blj179pg7pHI3ffp0WrdujYuLC7Vq1aJfv36cOnXKpExWVhZjxoyhevXqODs7M2DAABISEswUsfl89NFHaDQaxo0bZzxWle9NbGwsTz31FNWrV8fBwYHg4GD27dtnPK8oClOnTsXLywsHBwfCwsI4c+aMGSMuH3q9nilTpuDv74+DgwP169fn/fffN1l7tarcm61bt9KnTx+8vb3RaDSsWrXK5HxR7kNiYiJDhw7F1dUVNzc3Ro0aRVpaWskCUsR9W7JkiWJra6v873//U44dO6Y899xzipubm5KQkGDu0MpVeHi4smDBAuXo0aNKZGSk0qtXL8XX11dJS0szlnnhhRcUHx8fJSIiQtm3b5/y4IMPKu3atTNj1OVvz549St26dZVmzZopr776qvF4Vb03iYmJip+fnzJixAhl9+7dyvnz55V169YpZ8+eNZb56KOPFJ1Op6xatUo5dOiQ8uijjyr+/v5KZmamGSMve9OmTVOqV6+urF69WomKilKWL1+uODs7K5999pmxTFW5N3/++afy5ptvKitWrFAAZeXKlSbni3IfevTooTRv3lzZtWuXsm3bNqVBgwbKkCFDShSPJM9S0KZNG2XMmDHG53q9XvH29lamT59uxqjM7/LlywqgbNmyRVEURUlKSlJsbGyU5cuXG8ucOHFCAZSdO3eaK8xylZqaqgQEBCjr169XOnfubEyeVfneTJo0SenQoUOh5w0Gg+Lp6anMmjXLeCwpKUmxs7NTfv755/II0Wx69+6tjBw50uTYY489pgwdOlRRlKp7b25PnkW5D8ePH1cAZe/evcYya9euVTQajRIbG1vsGKTZ9j7l5OSwf/9+wsLCjMe0Wi1hYWHs3LnTjJGZX3JyMgDu7u4A7N+/n9zcXJN7FRgYiK+vb5W5V2PGjKF3794m9wCq9r35/fffCQkJ4fHHH6dWrVq0aNGCb7/91ng+KiqK+Ph4k3uj0+lo27Ztpb837dq1IyIigtOnTwNw6NAhtm/fTs+ePYGqfW9uVZT7sHPnTtzc3AgJCTGWCQsLQ6vVsnv37mK/pywMf5+uXr2KXq/Hw8PD5LiHhwcnT540U1TmZzAYGDduHO3bt6dp06YAxMfHY2tri5ubm0lZDw8P4uPjzRBl+VqyZAkHDhxg7969Bc5V5Xtz/vx5vvrqK8aPH8///d//sXfvXl555RVsbW0ZPny48fPf6Xesst+bN954g5SUFAIDA7GyskKv1zNt2jSGDh0KUKXvza2Kch/i4+OpVauWyXlra2vc3d1LdK8keYoyMWbMGI4ePcr27dvNHYpFiImJ4dVXX2X9+vXY29ubOxyLYjAYCAkJ4cMPPwSgRYsWHD16lPnz5zN8+HAzR2dey5YtY9GiRSxevJgmTZoQGRnJuHHj8Pb2rvL3xtyk2fY+1ahRAysrqwKjIhMSEvD09DRTVOY1duxYVq9ezaZNm0y2evP09CQnJ4ekpCST8lXhXu3fv5/Lly/TsmVLrK2tsba2ZsuWLcydOxdra2s8PDyq7L3x8vKicePGJseCgoKIjo4GMH7+qvg79vrrr/PGG28wePBggoODefrpp3nttdeYPn06ULXvza2Kch88PT25fPmyyfm8vDwSExNLdK8ked4nW1tbWrVqRUREhPGYwWAgIiKC0NBQM0ZW/hRFYezYsaxcuZKNGzfi7+9vcr5Vq1bY2NiY3KtTp04RHR1d6e9V9+7dOXLkCJGRkcZHSEgIQ4cONf5cVe9N+/btC0xpOn36NH5+fgD4+/vj6elpcm9SUlLYvXt3pb83GRkZBTZltrKywmAwAFX73tyqKPchNDSUpKQk9u/fbyyzceNGDAYDbdu2Lf6blni4kzBasmSJYmdnpyxcuFA5fvy4Mnr0aMXNzU2Jj483d2jl6sUXX1R0Op2yefNmJS4uzvjIyMgwlnnhhRcUX19fZePGjcq+ffuU0NBQJTQ01IxRm8+to20Vperemz179ijW1tbKtGnTlDNnziiLFi1SHB0dlZ9++slY5qOPPlLc3NyU3377TTl8+LDSt2/fSjkd43bDhw9XateubZyqsmLFCqVGjRrKxIkTjWWqyr1JTU1VDh48qBw8eFABlDlz5igHDx5ULly4oChK0e5Djx49lBYtWii7d+9Wtm/frgQEBMhUFXObN2+e4uvrq9ja2ipt2rRRdu3aZe6Qyh1wx8eCBQuMZTIzM5WXXnpJqVatmuLo6Kj0799fiYuLM1/QZnR78qzK9+aPP/5QmjZtqtjZ2SmBgYHKN998Y3LeYDAoU6ZMUTw8PBQ7Ozule/fuyqlTp8wUbflJSUlRXn31VcXX11ext7dX6tWrp7z55ptKdna2sUxVuTebNm2649+X4cOHK4pStPtw7do1ZciQIYqzs7Pi6uqqPPPMM0pqamqJ4pEtyYQQQohikj5PIYQQopgkeQohhBDFJMlTCCGEKCZJnkIIIUQxSfIUQgghikmSpxBCCFFMkjyFEEKIYpLkKYSFqlu3Lp9++mmRy2/evBmNRlNgfdzKqrj3R4jSJMlTiPuk0Wju+njnnXdKdN29e/cyevToIpdv164dcXFx6HS6Er2fEKLoZEsyIe5TXFyc8eelS5cydepUk4XOnZ2djT8rioJer8fa+t6/ejVr1ixWHLa2tlVqJw0hzElqnkLcJ09PT+NDp9Oh0WiMz0+ePImLiwtr166lVatW2NnZsX37ds6dO0ffvn3x8PDA2dmZ1q1bs2HDBpPr3t4sqdFo+O9//0v//v1xdHQkICCA33//3Xj+9mbbhQsX4ubmxrp16wgKCsLZ2ZkePXqYJPu8vDxeeeUV3NzcqF69OpMmTWL48OH069fvrp95+/btdOzYEQcHB3x8fHjllVdIT083if39999nyJAhODk5Ubt2bb744guTa0RHR9O3b1+cnZ1xdXVl0KBBBbaU+uOPP2jdujX29vbUqFGD/v37m5zPyMhg5MiRuLi44OvryzfffHPXuIUoLZI8hSgHb7zxBh999BEnTpygWbNmpKWl0atXLyIiIjh48CA9evSgT58+xj0sC/Puu+8yaNAgDh8+TK9evRg6dCiJiYmFls/IyGD27Nn8+OOPbN26lejoaCZMmGA8P2PGDBYtWsSCBQvYsWMHKSkprFq16q4xnDt3jh49ejBgwAAOHz7M0qVL2b59O2PHjjUpN2vWLJo3b87Bgwd54403jJuBg7ptX9++fUlMTGTLli2sX7+e8+fP88QTTxhfv2bNGvr370+vXr04ePAgERERtGnTxuQ9Pv74Y0JCQjh48CAvvfQSL774YoHtzYQoE/e1zL0QwsSCBQsUnU5nfJ6/E8SqVavu+domTZoo8+bNMz738/NTPvnkE+NzQHnrrbeMz9PS0hRAWbt2rcl7Xb9+3RgLoJw9e9b4mi+++ELx8PAwPvfw8FBmzZplfJ6Xl6f4+voqffv2LTTOUaNGKaNHjzY5tm3bNkWr1Rq3f/Lz81N69OhhUuaJJ55QevbsqSiKovz999+KlZWVEh0dbTx/7NgxBVD27NmjKIqihIaGKkOHDi00Dj8/P+Wpp54yPjcYDEqtWrWUr776qtDXCFFapOYpRDkICQkxeZ6WlsaECRMICgrCzc0NZ2dnTpw4cc+aZ7NmzYw/Ozk54erqyuXLlwst7+joSP369Y3Pvby8jOWTk5NJSEgwqc1ZWVnRqlWru8Zw6NAhFi5ciLOzs/ERHh6OwWAgKirKWO72zZhDQ0M5ceIEACdOnMDHxwcfHx/j+caNG+Pm5mYsExkZSffu3e8ay633I7+5/G73Q4jSIgOGhCgHTk5OJs8nTJjA+vXrmT17Ng0aNMDBwYGBAweSk5Nz1+vY2NiYPNdoNBgMhmKVV+5zF8K0tDSef/55XnnllQLnfH197+vat3JwcLhnmeLeDyFKi9Q8hTCDHTt2MGLECPr3709wcDCenp78+++/5RqDTqfDw8ODvXv3Go/p9XoOHDhw19e1bNmS48eP06BBgwIPW1tbY7ldu3aZvG7Xrl0EBQUBEBQURExMDDExMcbzx48fJykpicaNGwNqrTIiIuK+P6cQZUFqnkKYQUBAACtWrKBPnz5oNBqmTJlilhrTyy+/zPTp02nQoAGBgYHMmzeP69evo9FoCn3NpEmTePDBBxk7dizPPvssTk5OHD9+nPXr1/P5558by+3YsYOZM2fSr18/1q9fz/Lly1mzZg0AYWFhBAcHM3ToUD799FPy8vJ46aWX6Ny5s7GJ++2336Z79+7Ur1+fwYMHk5eXx59//smkSZPK9qYIUQRS8xTCDObMmUO1atVo164dffr0ITw8nJYtW5Z7HJMmTWLIkCEMGzaM0NBQY/+lvb19oa9p1qwZW7Zs4fTp03Ts2JEWLVowdepUvL29Tcr95z//Yd++fbRo0YIPPviAOXPmEB4eDqjNq7/99hvVqlWjU6dOhIWFUa9ePZYuXWp8fZcuXVi+fDm///47DzzwAN26dWPPnj1lcyOEKCaNcr8dIEKISsNgMBAUFMSgQYN4//33S3ydunXrMm7cOMaNG1d6wQlhQaTZVogq7MKFC/z999907tyZ7OxsPv/8c6KionjyySfNHZoQFk2abYWowrRaLQsXLqR169a0b9+eI0eOsGHDBuPAHiHEnUmzrRBCCFFMUvMUQgghikmSpxBCCFFMkjyFEEKIYpLkKYQQQhSTJE8hhBCimCR5CiGEEMUkyVMIIYQoJkmeQgghRDFJ8hRCCCGK6f8BCHBXluGNtLsAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN_Transformer(input_dim=train_x.shape[-1], output_dim=7, A=A, hidden_dim=train_x.shape[-1], num_gcn_layers=1)\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask,\n",
        "                                          X, valid_y, valid_mask,\n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNwZuLEEKU8W"
      },
      "outputs": [],
      "source": [
        "# hetrophilic task -> attending to everythig is better\n",
        "# homophilic task -> attending to graph is good\n",
        "\n",
        "# dont use cora !! --- highly homophilic\n",
        "# control homophily\n",
        "\n",
        "# cyclic object\n",
        "\n",
        "# get some results - do not fail the project\n",
        "# logit you can fit the forward pass and\n",
        "\n",
        "\n",
        "# if you want to switch from inductive and transductive\n",
        "# only modify the loss and not the forward pass\n",
        "\n",
        "# start with inductive.\n",
        "# contibue with transductive.\n",
        "\n",
        "\n",
        "# Use CLRS\n",
        "# --> NAR dataset\n",
        "# --> graph trnsformers\n",
        "\n",
        "\n",
        "# how well GNNs deal with over squashing?\n",
        "\n",
        "\n",
        "\n",
        "# 1. homophilly in the ocntext of transformer and GNN\n",
        "\n",
        "# Graph former\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
