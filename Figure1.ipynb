{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nRR5bUiLRZ5a"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1nYy2OQQ4os8qAJRaYQ2kwsbNjzw3zFyx",
      "authorship_tag": "ABX9TyO3eHYH6aUxzR70x5sHh2dJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batu-el/l65_be301_dc755/blob/main/Figure1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "nRR5bUiLRZ5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl torch_geometric torch\n",
        "\n",
        "# Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install networkx\n",
        "    !pip install lovely-tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLx8ARPERaaB",
        "outputId": "4c37b929-145d-4051-f379-ec52b70aa22f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch_geometric, nvidia-cusolver-cu12, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 torch_geometric-2.5.1\n",
            "Installing PyTorch Geometric\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling other libraries\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting lovely-tensors\n",
            "  Downloading lovely_tensors-0.1.15-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lovely-tensors) (2.2.1+cu121)\n",
            "Collecting lovely-numpy>=0.2.9 (from lovely-tensors)\n",
            "  Downloading lovely_numpy-0.2.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.25.2)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from lovely-numpy>=0.2.9->lovely-tensors) (1.5.29)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from lovely-numpy>=0.2.9->lovely-tensors) (7.34.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lovely-numpy>=0.2.9->lovely-tensors) (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->lovely-tensors) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->lovely-tensors) (12.4.99)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->lovely-numpy>=0.2.9->lovely-tensors) (24.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->lovely-numpy>=0.2.9->lovely-tensors)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->lovely-numpy>=0.2.9->lovely-tensors) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lovely-tensors) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lovely-tensors) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->lovely-numpy>=0.2.9->lovely-tensors) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lovely-numpy>=0.2.9->lovely-tensors) (1.16.0)\n",
            "Installing collected packages: jedi, lovely-numpy, lovely-tensors\n",
            "Successfully installed jedi-0.19.1 lovely-numpy-0.2.11 lovely-tensors-0.1.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, LayerNorm, Module, ModuleList, Sequential\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer, MultiheadAttention\n",
        "from torch.optim import Adam\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.datasets import Planetoid\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, dense_to_sparse, to_dense_batch, to_dense_adj\n",
        "\n",
        "from torch_geometric.nn import GCNConv, GATConv, GATv2Conv\n",
        "\n",
        "# from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "import lovely_tensors as lt\n",
        "lt.monkey_patch()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "# warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMiwOILkRgEP",
        "outputId": "459b1094-3bb6-4e8c-d81a-4aadf3038239"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.10/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.2.1+cu121\n",
            "PyG version 2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuVTx4otRi6i",
        "outputId": "d02cfbbe-dbda-45f7-cc97-d609424f27f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "g6R5GR7hRdEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import WebKB, WikipediaNetwork\n",
        "\n",
        "DATASETS = {}\n",
        "\n",
        "# Chamelion & Squirrel\n",
        "# Cora & Citeseer\n",
        "# Cornell & Texas & Wisconsin\n",
        "\n",
        "## Mid Size Datasets\n",
        "# Citation Networks\n",
        "dataset = 'Cora'\n",
        "dataset = Planetoid('/tmp/Cora', dataset)\n",
        "data = dataset[0]\n",
        "DATASETS['Cora'] = data\n",
        "dataset = 'Citeseer'\n",
        "dataset = Planetoid('/tmp/Citeseer', dataset)\n",
        "data = dataset[0]\n",
        "DATASETS['Citeseer'] = data\n",
        "# Wikipedia Pages\n",
        "dataset = 'Chameleon'\n",
        "dataset = WikipediaNetwork(root='/tmp/Chameleon', name='Chameleon')\n",
        "data = dataset[0]\n",
        "DATASETS['Chameleon'] = data\n",
        "dataset = 'Squirrel'\n",
        "dataset = WikipediaNetwork(root='/tmp/Squirrel', name='Squirrel')\n",
        "data = dataset[0]\n",
        "DATASETS['Squirrel'] = data\n",
        "### Small Sized Datasets\n",
        "# Web Pages\n",
        "dataset = WebKB(root='/tmp/Cornell', name='Cornell')\n",
        "data = dataset[0]\n",
        "DATASETS['Cornell'] = data\n",
        "dataset = WebKB(root='/tmp/Texas', name='Texas')\n",
        "data = dataset[0]\n",
        "DATASETS['Texas'] = data\n",
        "dataset = WebKB(root='/tmp/Wisconsin', name='Wisconsin')\n",
        "data = dataset[0]\n",
        "DATASETS['Wisconsin'] = data"
      ],
      "metadata": {
        "id": "8PVfelu6ReJe"
      },
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tqdm\n",
        "# ### Shortest Paths ###\n",
        "# def get_shortest_path_matrix(adjacency_matrix):\n",
        "#     graph = nx.from_numpy_array(adjacency_matrix.cpu().numpy(), create_using=nx.DiGraph)\n",
        "#     shortest_path_matrix = nx.floyd_warshall_numpy(graph)\n",
        "#     shortest_path_matrix = torch.tensor(shortest_path_matrix).float()\n",
        "#     return shortest_path_matrix\n",
        "\n",
        "# SHORTEST_PATHS = {}\n",
        "# for data_key in tqdm.tqdm(DATASETS):\n",
        "#   print(data_key)\n",
        "#   data = DATASETS[data_key]\n",
        "#   dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
        "#   dense_shortest_path_matrix = get_shortest_path_matrix(dense_adj)\n",
        "#   SHORTEST_PATHS[data_key] = dense_shortest_path_matrix\n",
        "\n",
        "# ### Save the Shortest Paths\n",
        "# import pickle\n",
        "# with open('sp_dict.pkl', 'wb') as f:\n",
        "#     pickle.dump(SHORTEST_PATHS, f)\n",
        "# import pickle\n",
        "# with open('drive/MyDrive/Colab Notebooks/L65_Project/shortest_paths/sp_dict.pkl', 'rb') as f:\n",
        "#     SHORTEST_PATHS = pickle.load(f)"
      ],
      "metadata": {
        "id": "PqcrQ7FuVa8c"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_key in DATASETS:\n",
        "  data = DATASETS[data_key]\n",
        "  data.dense_sp_matrix = SHORTEST_PATHS[data_key]\n",
        "  data.dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
        "  data.dense_adj = data.dense_adj.cuda() + torch.eye(data.dense_adj.shape[0]).cuda()\n",
        "  data = T.AddLaplacianEigenvectorPE(k = 16, attr_name = 'pos_enc')(data)\n",
        "  DATASETS[data_key] = data"
      ],
      "metadata": {
        "id": "hzEswGTMXoOI"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Masks ###\n",
        "\n",
        "def generate_masks(num_nodes=None,num_runs=None,train_ratio=None, val_ratio=None):\n",
        "    masks = { 'train_mask': np.zeros((num_nodes, num_runs), dtype=int),\n",
        "              'val_mask': np.zeros((num_nodes, num_runs), dtype=int),\n",
        "              'test_mask': np.zeros((num_nodes, num_runs), dtype=int)}\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        indices = np.arange(num_nodes)\n",
        "        np.random.shuffle(indices)\n",
        "        train_end = int(train_ratio * num_nodes)\n",
        "        val_end = train_end + int(val_ratio * num_nodes)\n",
        "        masks['train_mask'][indices[:train_end], run] = 1\n",
        "        masks['val_mask'][indices[train_end:val_end], run] = 1\n",
        "        masks['test_mask'][indices[val_end:], run] = 1\n",
        "\n",
        "    tensor_masks = {'train_mask': torch.tensor(masks['train_mask']),\n",
        "                    'val_mask':torch.tensor(masks['val_mask']),\n",
        "                    'test_mask':torch.tensor(masks['test_mask'])}\n",
        "    return tensor_masks\n",
        "\n",
        "for data_key in DATASETS:\n",
        "    data = DATASETS[data_key]\n",
        "\n",
        "    masks = generate_masks(num_nodes=data.x.shape[0], num_runs=10, train_ratio=0.4, val_ratio=0.3)\n",
        "    data.train_mask = masks['train_mask']\n",
        "    data.val_mask = masks['val_mask']\n",
        "    data.test_mask = masks['test_mask']\n",
        "\n",
        "    if len(data.train_mask.shape)==1:\n",
        "      print('Add 10 Masks')\n",
        "    else:\n",
        "      print('We have 10 Masks')\n",
        "      print('Train Ratio:',(data.train_mask[:,0].sum() / len(data.train_mask[:,0])).item())\n",
        "      print('Val Ratio:',(data.val_mask[:,0].sum() / len(data.val_mask[:,0])).item())\n",
        "      print('Test Ratio:',(data.test_mask[:,0].sum() / len(data.test_mask[:,0])).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsqv_LTEU-2H",
        "outputId": "7069e75b-2a61-4614-ce34-bf66bbdcdc5f"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 10 Masks\n",
            "Train Ratio: 0.39992615580558777\n",
            "Val Ratio: 0.29985228180885315\n",
            "Test Ratio: 0.3002215623855591\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.39975953102111816\n",
            "Val Ratio: 0.29996994137763977\n",
            "Test Ratio: 0.30027052760124207\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.39964866638183594\n",
            "Val Ratio: 0.2999560832977295\n",
            "Test Ratio: 0.30039525032043457\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.39992308616638184\n",
            "Val Ratio: 0.2999423146247864\n",
            "Test Ratio: 0.3001345992088318\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.3989070951938629\n",
            "Val Ratio: 0.2950819730758667\n",
            "Test Ratio: 0.3060109317302704\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.3989070951938629\n",
            "Val Ratio: 0.2950819730758667\n",
            "Test Ratio: 0.3060109317302704\n",
            "We have 10 Masks\n",
            "Train Ratio: 0.39840638637542725\n",
            "Val Ratio: 0.29880478978157043\n",
            "Test Ratio: 0.3027888536453247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASETS['Cora']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_JS1GdyqJ76",
        "outputId": "8fcad010-64c8-4afa-ba7e-117fabdb71dd"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708, 10], val_mask=[2708, 10], test_mask=[2708, 10], dense_sp_matrix=[2708, 2708], dense_adj=[2708, 2708], pos_enc=[2708, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "7JV4ZtidSENR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyG example code: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gcn2_cora.py\n",
        "\n",
        "class GNNModel(Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_dim: int = data.x.shape[-1],\n",
        "            hidden_dim: int = 128,\n",
        "            num_heads: int = 1,\n",
        "            num_layers: int = 1,\n",
        "            out_dim: int = len(data.y.unique()),\n",
        "            dropout: float = 0.5,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin_in = Linear(in_dim, hidden_dim)\n",
        "        self.lin_out = Linear(hidden_dim, out_dim)\n",
        "        self.layers = ModuleList()\n",
        "\n",
        "        for layer in range(num_layers):\n",
        "            self.layers.append(\n",
        "                GCNConv(hidden_dim, hidden_dim)\n",
        "            )\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "        x = self.lin_in(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # conv -> activation ->  dropout -> residual\n",
        "            x_in = x\n",
        "            x = layer(x, edge_index)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, self.dropout, training=self.training)\n",
        "            x = x_in + x\n",
        "\n",
        "        x = self.lin_out(x)\n",
        "\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "class SparseGraphTransformerModel(Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_dim: int = data.x.shape[-1],\n",
        "            hidden_dim: int = 128,\n",
        "            num_heads: int = 1,\n",
        "            num_layers: int = 1,\n",
        "            out_dim: int = len(data.y.unique()),\n",
        "            dropout: float = 0.5,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin_in = Linear(in_dim, hidden_dim)\n",
        "        self.lin_out = Linear(hidden_dim, out_dim)\n",
        "\n",
        "        self.layers = ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.layers.append(\n",
        "                MultiheadAttention(\n",
        "                    embed_dim = hidden_dim,\n",
        "                    num_heads = num_heads,\n",
        "                    dropout = dropout\n",
        "                )\n",
        "            )\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, dense_adj):\n",
        "\n",
        "        x = self.lin_in(x)\n",
        "\n",
        "        self.attn_weights_list = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x_in = x\n",
        "            x, attn_weights = layer(\n",
        "                x, x, x,\n",
        "                attn_mask = ~dense_adj.bool(),\n",
        "                average_attn_weights = False\n",
        "            )\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, self.dropout, training=self.training)\n",
        "            x = x_in + x\n",
        "\n",
        "            self.attn_weights_list.append(attn_weights)\n",
        "\n",
        "        x = self.lin_out(x)\n",
        "\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "class DenseGraphTransformerModel(Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_dim: int = data.x.shape[-1],\n",
        "            pos_enc_dim: int = 16,\n",
        "            hidden_dim: int = 128,\n",
        "            num_heads: int = 1,\n",
        "            num_layers: int = 1,\n",
        "            out_dim: int = len(data.y.unique()),\n",
        "            dropout: float = 0.5,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin_in = Linear(in_dim, hidden_dim)\n",
        "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
        "        self.lin_out = Linear(hidden_dim, out_dim)\n",
        "\n",
        "        self.layers = ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.layers.append(\n",
        "                MultiheadAttention(\n",
        "                    embed_dim = hidden_dim,\n",
        "                    num_heads = num_heads,\n",
        "                    dropout = dropout\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
        "\n",
        "        # x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
        "        x = self.lin_in(x)  # no node positional encoding\n",
        "\n",
        "        # attention bias\n",
        "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
        "        # diagonals -> self connection, set to 0\n",
        "        # disconnected nodes -> -1\n",
        "        attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
        "            (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
        "            nan=0, posinf=0, neginf=0\n",
        "        )\n",
        "        #attn_bias = torch.ones_like(attn_bias)\n",
        "\n",
        "        # TransformerEncoder\n",
        "        # x = self.encoder(x, mask = attn_bias)\n",
        "\n",
        "        self.attn_weights_list = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # MHSA layer\n",
        "            # float mask adds learnable additive attention bias\n",
        "            x_in = x\n",
        "            x, attn_weights = layer(\n",
        "                x, x, x,\n",
        "                attn_mask = attn_bias,\n",
        "                average_attn_weights = False\n",
        "            )\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, self.dropout, training=self.training)\n",
        "            x = x_in + x\n",
        "\n",
        "            self.attn_weights_list.append(attn_weights)\n",
        "\n",
        "        x = self.lin_out(x)\n",
        "\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "class DenseGraphTransformerModel_V2(Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_dim: int = data.x.shape[-1],\n",
        "            pos_enc_dim: int = 16,\n",
        "            hidden_dim: int = 128,\n",
        "            num_heads: int = 1,\n",
        "            num_layers: int = 1,\n",
        "            out_dim: int = len(data.y.unique()),\n",
        "            dropout: float = 0.5,\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lin_in = Linear(in_dim, hidden_dim)\n",
        "        self.lin_pos_enc = Linear(pos_enc_dim, hidden_dim)\n",
        "        self.lin_out = Linear(hidden_dim, out_dim)\n",
        "\n",
        "        self.layers = ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.layers.append(\n",
        "                MultiheadAttention(\n",
        "                    embed_dim = hidden_dim,\n",
        "                    num_heads = num_heads,\n",
        "                    dropout = dropout\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "        self.attn_bias_scale = torch.nn.Parameter(torch.tensor([10.0]))  # controls how much we initially bias our model to nearby nodes\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, pos_enc, dense_sp_matrix):\n",
        "\n",
        "        x = self.lin_in(x) + self.lin_pos_enc(pos_enc)\n",
        "        # x = self.lin_in(x)  # no node positional encoding\n",
        "\n",
        "        # attention bias\n",
        "        # [i, j] -> inverse of shortest path distance b/w node i and j\n",
        "        # diagonals -> self connection, set to 0\n",
        "        # disconnected nodes -> -1\n",
        "        # attn_bias = self.attn_bias_scale * torch.nan_to_num(\n",
        "        #     (1 / (torch.nan_to_num(dense_sp_matrix, nan=-1, posinf=-1, neginf=-1))),\n",
        "        #     nan=0, posinf=0, neginf=0\n",
        "        # )\n",
        "        #attn_bias = torch.ones_like(attn_bias)\n",
        "\n",
        "        # TransformerEncoder\n",
        "        # x = self.encoder(x, mask = attn_bias)\n",
        "\n",
        "        self.attn_weights_list = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # # TransformerEncoderLayer\n",
        "            # # float mask adds learnable additive attention bias\n",
        "            # x = layer(x, src_mask = attn_bias)\n",
        "\n",
        "            # MHSA layer\n",
        "            # float mask adds learnable additive attention bias\n",
        "            x_in = x\n",
        "            x, attn_weights = layer(\n",
        "                x, x, x,\n",
        "                # attn_mask = attn_bias,\n",
        "                average_attn_weights = False\n",
        "            )\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, self.dropout, training=self.training)\n",
        "            x = x_in + x\n",
        "\n",
        "            self.attn_weights_list.append(attn_weights)\n",
        "\n",
        "        x = self.lin_out(x)\n",
        "\n",
        "        return x.log_softmax(dim=-1)"
      ],
      "metadata": {
        "id": "AKL9b7tCSDDd"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainers"
      ],
      "metadata": {
        "id": "Z39ODu9oT2f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_GCN(NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              data):\n",
        "\n",
        "    IN_DIM = data.x.shape[-1]\n",
        "    OUT_DIM = len(data.y.unique())\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = GNNModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return float(loss)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test():\n",
        "        model.eval()\n",
        "        pred, accs = model(data.x, data.edge_index).argmax(dim=-1), []\n",
        "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "        return accs\n",
        "\n",
        "    best_val_acc = test_acc = 0\n",
        "    times = []\n",
        "    for epoch in range(1, 100):\n",
        "        start = time.time()\n",
        "        loss = train()\n",
        "        train_acc, val_acc, tmp_test_acc = test()\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc = tmp_test_acc\n",
        "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
        "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
        "        #       f'Final Test: {test_acc:.4f}')\n",
        "        times.append(time.time() - start)\n",
        "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
        "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, None\n",
        "\n",
        "def Train_SparseGraphTransformerModel(NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              data):\n",
        "\n",
        "    IN_DIM = data.x.shape[-1]\n",
        "    OUT_DIM = len(data.y.unique())\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = SparseGraphTransformerModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.dense_adj)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return float(loss)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test():\n",
        "        model.eval()\n",
        "        pred, accs = model(data.x, data.dense_adj).argmax(dim=-1), []\n",
        "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "        return accs\n",
        "\n",
        "    best_val_acc = test_acc = 0\n",
        "    times = []\n",
        "    for epoch in range(1, 100):\n",
        "        start = time.time()\n",
        "        loss = train()\n",
        "        train_acc, val_acc, tmp_test_acc = test()\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc = tmp_test_acc\n",
        "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
        "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
        "        #       f'Final Test: {test_acc:.4f}')\n",
        "        times.append(time.time() - start)\n",
        "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
        "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
        "\n",
        "def Train_DenseGraphTransformerModel(NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              data):\n",
        "\n",
        "    IN_DIM = data.x.shape[-1]\n",
        "    OUT_DIM = len(data.y.unique())\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = DenseGraphTransformerModel(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        # print(data.pos_enc)\n",
        "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return float(loss)\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test():\n",
        "        model.eval()\n",
        "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
        "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "        return accs\n",
        "\n",
        "\n",
        "    best_val_acc = test_acc = 0\n",
        "    times = []\n",
        "    for epoch in range(1, 100):\n",
        "        start = time.time()\n",
        "        loss = train()\n",
        "        train_acc, val_acc, tmp_test_acc = test()\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc = tmp_test_acc\n",
        "        # print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
        "        #       f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
        "        #       f'Final Test: {test_acc:.4f}')\n",
        "        times.append(time.time() - start)\n",
        "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
        "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
        "\n",
        "    # Notes\n",
        "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
        "    # - Node positional encodings are not particularly useful\n",
        "    # - Edge distance encodings are very useful\n",
        "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes\n",
        "\n",
        "def Train_DenseGraphTransformerModel_V2(NUM_LAYERS,\n",
        "              NUM_HEADS,\n",
        "              data):\n",
        "\n",
        "    IN_DIM = data.x.shape[-1]\n",
        "    OUT_DIM = len(data.y.unique())\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = DenseGraphTransformerModel_V2(num_layers=NUM_LAYERS, num_heads=NUM_HEADS, in_dim=IN_DIM,out_dim=OUT_DIM).to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.pos_enc, data.dense_sp_matrix)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return float(loss)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test():\n",
        "        model.eval()\n",
        "        pred, accs = model(data.x, data.pos_enc, data.dense_sp_matrix).argmax(dim=-1), []\n",
        "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "            accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
        "        return accs\n",
        "\n",
        "    best_val_acc = test_acc = 0\n",
        "    times = []\n",
        "    for epoch in range(1, 100):\n",
        "        start = time.time()\n",
        "        loss = train()\n",
        "        train_acc, val_acc, tmp_test_acc = test()\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            test_acc = tmp_test_acc\n",
        "        print(f'Epoch: {epoch:04d}, Loss: {loss:.4f} Train: {train_acc:.4f}, '\n",
        "              f'Val: {val_acc:.4f}, Test: {tmp_test_acc:.4f}, '\n",
        "              f'Final Test: {test_acc:.4f}')\n",
        "        times.append(time.time() - start)\n",
        "    # print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")\n",
        "    return {'train_acc':train_acc,'val_acc':val_acc,'test_acc':test_acc}, model.attn_weights_list\n",
        "\n",
        "    # Notes\n",
        "    # - Dense Transformer needs to be trained for a bit longer to reach low loss value\n",
        "    # - Node positional encodings are not particularly useful\n",
        "    # - Edge distance encodings are very useful\n",
        "    # - Since Cora is highly homophilic, it is important to bias the attention towards nearby nodes"
      ],
      "metadata": {
        "id": "bgXWrDZ5V_al"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "X3wGJPl3YJcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Train Cora ###\n",
        "NUM_LAYERS = 1\n",
        "NUM_HEADS = 1\n",
        "NUM_RUNS = 10\n",
        "# data_key = 'Wisconsin'\n",
        "all_stats = {}\n",
        "for data_key in DATASETS:\n",
        "    print(f'Training on {data_key}')\n",
        "    data = DATASETS[data_key]\n",
        "\n",
        "    TRAIN_MASKS = data.train_mask\n",
        "    VAL_MASKS = data.val_mask\n",
        "    TEST_MASKS = data.test_mask\n",
        "\n",
        "    run_stats = {}\n",
        "\n",
        "    for mask_idx in tqdm.tqdm(range(NUM_RUNS)):\n",
        "        data.train_mask = TRAIN_MASKS[:,mask_idx]\n",
        "        data.val_mask = VAL_MASKS[:,mask_idx]\n",
        "        data.test_mask = TEST_MASKS[:,mask_idx]\n",
        "\n",
        "        accuracy_statistics = {}\n",
        "        attn_weights = {}\n",
        "\n",
        "        accuracy_statistics['GCN'], attn_weights['GCN'] = Train_GCN(NUM_LAYERS, NUM_HEADS, data)\n",
        "        accuracy_statistics['SparseGraphTransformerModel'] , attn_weights['SparseGraphTransformerModel'] = Train_SparseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
        "        accuracy_statistics['DenseGraphTransformerModel'] , attn_weights['DenseGraphTransformerModel'] = Train_DenseGraphTransformerModel(NUM_LAYERS, NUM_HEADS, data)\n",
        "        accuracy_statistics['DenseGraphTransformerModel_V2'] , attn_weights['DenseGraphTransformerModel_V2'] = Train_DenseGraphTransformerModel_V2(NUM_LAYERS, NUM_HEADS, data)\n",
        "        run_stats[mask_idx] = {'accuracy': accuracy_statistics,\n",
        "                              'attentions': attn_weights}\n",
        "    all_stats[data_key] = run_stats\n",
        "    data.train_mask = TRAIN_MASKS\n",
        "    data.val_mask = VAL_MASKS\n",
        "    data.test_mask = TEST_MASKS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "y6GoLurKW57q",
        "outputId": "fd3f59d0-3656-4e24-82ae-e099d380f628"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Cora\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor 0.400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_stats['Cora'][0]['attentions']['SparseGraphTransformerModel'][0][0].cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ7t8FIIoaAT",
        "outputId": "59b1d9ff-daf6-4cd9-9d6e-03cbbf2ac7a9"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28004393, 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.26722106, 0.22479795, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.16245243, 0.16671936, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.49980482, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.20004381,\n",
              "        0.19926256],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.20042647,\n",
              "        0.1991029 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Accuracy Statistics ###\n",
        "### Table 1 ###\n",
        "all_stats_df = {}\n",
        "for data_key in all_stats:\n",
        "  run_stats = all_stats[data_key]\n",
        "  table1 = pd.concat({key : pd.DataFrame(run_stats[key]['accuracy']) for key in run_stats}, axis=0)\n",
        "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
        "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
        "  table1 = pd.concat({'Train': table1_train, 'Test': table1_test}, axis=1)\n",
        "  all_stats_df[data_key] = table1\n",
        "pd.concat(all_stats_df, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNkbWu7zH06U",
        "outputId": "11242a57-55e5-4585-e971-d4f69bb33280"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:7: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_train = pd.concat({'mean': table1.mean(level=1, axis=0).loc['train_acc'], 'std':table1.std(level=1).loc['train_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.median(level=1) should use df.groupby(level=1).median().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n",
            "<ipython-input-316-c6d22e6c6f39>:8: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.var(level=1) should use df.groupby(level=1).var().\n",
            "  table1_test = pd.concat({'mean': table1.mean(level=1, axis=0).loc['test_acc'], 'std':table1.std(level=1).loc['test_acc']}, axis=1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Cora                      Citeseer       \\\n",
              "                                  Train           Test          Train        \n",
              "                                   mean  std      mean  std      mean  std   \n",
              "GCN                            2.500462  0.0  3.330873  0.0  2.501504  0.0   \n",
              "SparseGraphTransformerModel    2.500462  0.0  3.330873  0.0  2.501504  0.0   \n",
              "DenseGraphTransformerModel     2.500462  0.0  3.330873  0.0  2.501504  0.0   \n",
              "DenseGraphTransformerModel_V2  2.500462  0.0  3.330873  0.0  2.501504  0.0   \n",
              "\n",
              "                                            Chameleon       ...   Cornell  \\\n",
              "                                  Test          Train       ...      Test   \n",
              "                                  mean  std      mean  std  ...      mean   \n",
              "GCN                            3.33033  0.0  2.502198  0.0  ...  3.267857   \n",
              "SparseGraphTransformerModel    3.33033  0.0  2.502198  0.0  ...  3.267857   \n",
              "DenseGraphTransformerModel     3.33033  0.0  2.502198  0.0  ...  3.267857   \n",
              "DenseGraphTransformerModel_V2  3.33033  0.0  2.502198  0.0  ...  3.267857   \n",
              "\n",
              "                                       Texas                     Wisconsin  \\\n",
              "                                       Train           Test          Train   \n",
              "                               std      mean  std      mean  std      mean   \n",
              "GCN                            0.0  2.506849  0.0  3.267857  0.0      2.51   \n",
              "SparseGraphTransformerModel    0.0  2.506849  0.0  3.267857  0.0      2.51   \n",
              "DenseGraphTransformerModel     0.0  2.506849  0.0  3.267857  0.0      2.51   \n",
              "DenseGraphTransformerModel_V2  0.0  2.506849  0.0  3.267857  0.0      2.51   \n",
              "\n",
              "                                                   \n",
              "                                        Test       \n",
              "                               std      mean  std  \n",
              "GCN                            0.0  3.302632  0.0  \n",
              "SparseGraphTransformerModel    0.0  3.302632  0.0  \n",
              "DenseGraphTransformerModel     0.0  3.302632  0.0  \n",
              "DenseGraphTransformerModel_V2  0.0  3.302632  0.0  \n",
              "\n",
              "[4 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4183a25-06ae-47b5-81fe-6fa947f3454b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">Cora</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Citeseer</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Chameleon</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Cornell</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Texas</th>\n",
              "      <th colspan=\"4\" halign=\"left\">Wisconsin</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Train</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Test</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Train</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Test</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Train</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Test</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Train</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Test</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Train</th>\n",
              "      <th colspan=\"2\" halign=\"left\">Test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>...</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GCN</th>\n",
              "      <td>2.500462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.330873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.501504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.502198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.506849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.302632</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SparseGraphTransformerModel</th>\n",
              "      <td>2.500462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.330873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.501504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.502198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.506849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.302632</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DenseGraphTransformerModel</th>\n",
              "      <td>2.500462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.330873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.501504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.502198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.506849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.302632</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DenseGraphTransformerModel_V2</th>\n",
              "      <td>2.500462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.330873</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.501504</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33033</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.502198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.506849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.267857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.302632</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4183a25-06ae-47b5-81fe-6fa947f3454b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f4183a25-06ae-47b5-81fe-6fa947f3454b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f4183a25-06ae-47b5-81fe-6fa947f3454b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea282a98-cf7a-445b-abef-cb8e2f5755e5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea282a98-cf7a-445b-abef-cb8e2f5755e5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea282a98-cf7a-445b-abef-cb8e2f5755e5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Homophily Levels ###\n",
        "### Table 2 ###\n",
        "\n",
        "Homophily_Levels = {}\n",
        "\n",
        "for data_key in DATASETS:\n",
        "  data = DATASETS[data_key]\n",
        "  edge_index_tensor = torch.tensor(data.edge_index.cpu().numpy(), dtype=torch.long)\n",
        "  g = dgl.graph((edge_index_tensor[0], edge_index_tensor[1]), num_nodes=data.x.shape[0])\n",
        "  g.ndata['y'] = torch.tensor(data.y.cpu().numpy(), dtype=torch.long)\n",
        "  Homophily_Levels[data_key] = {'Node Homophily':dgl.node_homophily(g, g.ndata['y']),\n",
        "                                'Edge Homophily':dgl.edge_homophily(g, g.ndata['y']),\n",
        "                                'Adjusted Homophily':dgl.adjusted_homophily(g, g.ndata['y'])\n",
        "                                }\n",
        "pd.DataFrame(Homophily_Levels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "tLVnatHAM59o",
        "outputId": "4940989d-f896-4c0b-a807-ba6b36782df1"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Cora   Cornell     Texas  Wisconsin\n",
              "Node Homophily      0.825158  0.105744  0.065398   0.171916\n",
              "Edge Homophily      0.809966  0.130872  0.107692   0.196117\n",
              "Adjusted Homophily  0.771085 -0.211433 -0.258719  -0.152409"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-582e0ed8-2720-430b-8270-0c372ae68581\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cora</th>\n",
              "      <th>Cornell</th>\n",
              "      <th>Texas</th>\n",
              "      <th>Wisconsin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Node Homophily</th>\n",
              "      <td>0.825158</td>\n",
              "      <td>0.105744</td>\n",
              "      <td>0.065398</td>\n",
              "      <td>0.171916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Edge Homophily</th>\n",
              "      <td>0.809966</td>\n",
              "      <td>0.130872</td>\n",
              "      <td>0.107692</td>\n",
              "      <td>0.196117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adjusted Homophily</th>\n",
              "      <td>0.771085</td>\n",
              "      <td>-0.211433</td>\n",
              "      <td>-0.258719</td>\n",
              "      <td>-0.152409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-582e0ed8-2720-430b-8270-0c372ae68581')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-582e0ed8-2720-430b-8270-0c372ae68581 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-582e0ed8-2720-430b-8270-0c372ae68581');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff07dcb9-a389-4df8-aa99-302c1cb7fdba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff07dcb9-a389-4df8-aa99-302c1cb7fdba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff07dcb9-a389-4df8-aa99-302c1cb7fdba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Cora\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027887618218313568,\n        \"min\": 0.7710854411125183,\n        \"max\": 0.825157880783081,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.825157880783081,\n          0.8099659085273743,\n          0.7710854411125183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cornell\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19079045876952308,\n        \"min\": -0.21143309772014618,\n        \"max\": 0.13087248802185059,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.10574422031641006,\n          0.13087248802185059,\n          -0.21143309772014618\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Texas\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20045709530614614,\n        \"min\": -0.25871923565864563,\n        \"max\": 0.10769230872392654,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.06539812684059143,\n          0.10769230872392654,\n          -0.25871923565864563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wisconsin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19461164809108658,\n        \"min\": -0.1524089127779007,\n        \"max\": 0.19611650705337524,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.17191579937934875,\n          0.19611650705337524,\n          -0.1524089127779007\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Figure 1 ###\n",
        "\n",
        "for data_key in DATASETS\n",
        "  attn = attn_weights[data_key][0].cpu().numpy()[0]\n",
        "  sp = data.dense_sp_matrix.cpu().numpy()\n",
        "  sp[sp == np.inf] = np.nan\n",
        "  adj = data.dense_adj.cpu().numpy()\n",
        "  adj + np.eye(adj.shape[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "h26UoYnpMoRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "\n",
        "# Assuming edge_index is a NumPy array or a similar structure where\n",
        "# each column [u, v] represents an edge from node u to node v.\n",
        "# Also assuming x is a feature matrix where each row corresponds to node features.\n",
        "\n",
        "# Convert edge_index to a tensor\n",
        "\n",
        "# Create a DGL graph\n",
        "\n",
        "# Add node features\n",
        "g.ndata['x'] = torch.tensor(data.x.cpu().numpy(), dtype=torch.float)\n",
        "\n",
        "# If y, train_mask, val_mask, test_mask are provided, they can also be added\n",
        "g.ndata['train_mask'] = torch.tensor(data.train_mask.cpu().numpy(), dtype=torch.bool)\n",
        "g.ndata['val_mask'] = torch.tensor(data.val_mask.cpu().numpy(), dtype=torch.bool)\n",
        "g.ndata['test_mask'] = torch.tensor(data.test_mask.cpu().numpy(), dtype=torch.bool)\n",
        "\n",
        "# If you need to use the dense adjacency matrix directly\n",
        "# Note: DGL works with sparse matrices for efficiency, so typically you wouldn't convert to dense\n",
        "dense_adj_tensor = torch.tensor(dense_adj, dtype=torch.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhej3Kz32eTG",
        "outputId": "55fcc492-e6ed-4e6e-93a1-40394d3ca335"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-100-4b03353be905>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  dense_adj_tensor = torch.tensor(dense_adj, dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ6AgEhV7J5d",
        "outputId": "8f989f7f-30cd-4c66-8b1a-5f699de4b7da"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.825157880783081"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpmAZwnt8igi",
        "outputId": "136e5a19-9ec3-4464-fb83-fc780e6b7a61"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2708, 2708)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Creating a scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(sp, attn, color='blue')\n",
        "plt.title('Scatter plot of flat_attn vs. flat_sp')\n",
        "plt.xlabel('flat_sp')\n",
        "plt.ylabel('flat_attn')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "GFl2Z66_0UXc",
        "outputId": "1ddf49d6-e520-40a8-92fd-9772fc9d9ed1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn[adj == 0].mean(), attn[adj == 1].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGIr-YFj1R4c",
        "outputId": "c8ff545c-d5f3-4b8b-f468-604114e93e22"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.674604e-05, 0.18942371)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flat_attn.shape, flat_sp.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3BMZAn6y1XL",
        "outputId": "571cb009-d102-40be-ee5c-33a031d00406"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7333264,), (7333264,))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Oo7D4RA_Wwxh",
        "outputId": "2d6af57b-e694-4872-b2af-1fcd70482d1b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             GCN  SparseGraphTransformerModel  DenseGraphTransformerModel  \\\n",
              "train_acc  1.000                        1.000                       1.000   \n",
              "val_acc    0.710                        0.752                       0.748   \n",
              "test_acc   0.709                        0.758                       0.743   \n",
              "\n",
              "           DenseGraphTransformerModel_V2  \n",
              "train_acc                          1.000  \n",
              "val_acc                            0.394  \n",
              "test_acc                           0.529  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ccd7c40-ea16-4574-a966-b6134725bc0e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GCN</th>\n",
              "      <th>SparseGraphTransformerModel</th>\n",
              "      <th>DenseGraphTransformerModel</th>\n",
              "      <th>DenseGraphTransformerModel_V2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_acc</th>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_acc</th>\n",
              "      <td>0.710</td>\n",
              "      <td>0.752</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_acc</th>\n",
              "      <td>0.709</td>\n",
              "      <td>0.758</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ccd7c40-ea16-4574-a966-b6134725bc0e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ccd7c40-ea16-4574-a966-b6134725bc0e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ccd7c40-ea16-4574-a966-b6134725bc0e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0965886e-cfbb-4804-840f-28c962d17f39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0965886e-cfbb-4804-840f-28c962d17f39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0965886e-cfbb-4804-840f-28c962d17f39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"GCN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16772099848657396,\n        \"min\": 0.709,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.71,\n          0.709\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SparseGraphTransformerModel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14148262555286897,\n        \"min\": 0.752,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.752,\n          0.758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DenseGraphTransformerModel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14695690978424028,\n        \"min\": 0.743,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.748,\n          0.743\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DenseGraphTransformerModel_V2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31814619281078943,\n        \"min\": 0.394,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.394,\n          0.529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "NUM_LAYERS = 1\n",
        "NUM_HEADS = 1\n",
        "IN_DIM = data.x.shape[-1]\n",
        "OUT_DIM = len(data.y.unique())\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "MODELS = {\n",
        "    'GNNModel': GNNModel(num_layers = NUM_LAYERS, num_heads = NUM_HEADS, in_dim = IN_DIM, out_dim = OUT_DIM).to(device),\n",
        "    'SparseGraphTransformerModel': SparseGraphTransformerModel(num_layers = NUM_LAYERS, num_heads = NUM_HEADS, in_dim = IN_DIM, out_dim = OUT_DIM).to(device),\n",
        "    'DenseGraphTransformerModel': DenseGraphTransformerModel(num_layers = NUM_LAYERS, num_heads = NUM_HEADS, in_dim = IN_DIM, out_dim = OUT_DIM).to(device),\n",
        "    'DenseGraphTransformerModel_V2': DenseGraphTransformerModel_V2(num_layers = NUM_LAYERS, num_heads = NUM_HEADS, in_dim = IN_DIM, out_dim = OUT_DIM).to(device)\n",
        "          }\n",
        "\n",
        "\n",
        "data = T.AddLaplacianEigenvectorPE(k = 16, attr_name = 'pos_enc')(data)\n",
        "data.dense_adj = to_dense_adj(data.edge_index, max_num_nodes = data.x.shape[0])[0]\n",
        "data.dense_sp_matrix = dense_shortest_path_matrix.float()  # pre-computed in previous cell\n",
        "\n",
        "\n",
        "model =\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AaxWOpRcT3oY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}